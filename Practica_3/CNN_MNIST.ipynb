{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "no15HlrVN74A"
      },
      "source": [
        "### Importación de Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YxpqPv8PN74B",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZzmnKDF1N74E"
      },
      "source": [
        "### Importación de datos "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7WEGuQHzN74F",
        "outputId": "d770531f-733f-4fcb-86cf-670cdf083eb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"input/data/\", one_hot = True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-3-ce8afb69b99e>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting input/data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting input/data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting input/data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting input/data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1TV-Nfg0N74K"
      },
      "source": [
        "### verificando los datos de prueba"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "udNyagobN74L",
        "outputId": "c689de04-06d1-4242-f728-45c11719941a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "mnist.train.images.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(55000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-gSCC-PjN74P",
        "colab": {}
      },
      "source": [
        "imagendemo=np.reshape(mnist.train.images[2,:],(28,28))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-EdsFGZNN74S",
        "outputId": "1e85bd24-a66b-40b8-f214-bf1e23d40ab1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plt.imshow(imagendemo,cmap='gray')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f5f38570400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nO5AEYQeSIOxAEoQdSIKwA0kQdiCJ/wcBfP2iewWGQAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8GVvt8kCN74V"
      },
      "source": [
        "### Declarando la arquitectura\n",
        "\n",
        "Generando función "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l-VpFXQpN74V",
        "colab": {}
      },
      "source": [
        "def Neural_network_model(\n",
        "    n_nodes_hl1=500,\n",
        "    n_nodes_hl2=500,\n",
        "    n_nodes_hl3=500,\n",
        "    keep_rate = 0.8,\n",
        "    n_classes=10\n",
        "    ):\n",
        "    # Declarando las entradas y salidas\n",
        "    x=tf.placeholder('float',[None,784])\n",
        "    y=tf.placeholder('float')\n",
        "    \n",
        "    #Imagenes \n",
        "    img = tf.reshape(x, shape=[-1, 28, 28, 1]) #Dimensiones de la imagen (28*28*1), -1 = indica que mantenga el tamaño del batch en las entradas(x)\n",
        "    # Declarando las variables \n",
        "    weights = {'W_conv1':tf.Variable(tf.random_normal([5,5,1,32])), #Primeras dos dimensiones son el tamaño del kernel, 3 argumento=profundidad del kernel, 4to argumento = número de filtros(neuronas) de este tipo que requiero\n",
        "               'W_conv2':tf.Variable(tf.random_normal([5,5,32,64])),\n",
        "               'W_conv3':tf.Variable(tf.random_normal([5,5,64,128])),\n",
        "               'W_fc':tf.Variable(tf.random_normal([4*4*128,1024])),\n",
        "               'out':tf.Variable(tf.random_normal([1024, n_classes]))}\n",
        "\n",
        "    biases = {'b_conv1':tf.Variable(tf.random_normal([32])),\n",
        "               'b_conv2':tf.Variable(tf.random_normal([64])),\n",
        "              'b_conv3':tf.Variable(tf.random_normal([128])),\n",
        "               'b_fc':tf.Variable(tf.random_normal([1024])),\n",
        "               'out':tf.Variable(tf.random_normal([n_classes]))}\n",
        "   \n",
        "    \n",
        "    \n",
        "    # Declarando la arquitectura\n",
        "    #Recibe imagen de 28*28*1\n",
        "    #Primer convolución\n",
        "    \"\"\"\n",
        "    stride[0] = marca saltos entre las imagenes de un batch\n",
        "\n",
        "    stride[1] y stride[2] son los strides espaciales \n",
        "\n",
        "    stride[3] = stride de profundidad, marca los saltos entre cada capa del kernel, en este caso va a ir de 1 en 1\n",
        "    lo que indica que ira recorriendo cada kernel 1 a 1\n",
        "    \"\"\"\n",
        "    l1 = tf.nn.conv2d(img, weights['W_conv1'], strides=[1,1,1,1], padding='SAME') \n",
        "\n",
        "    l1 = tf.add(l1, biases['b_conv1'])\n",
        "    l1 = tf.nn.relu(l1)\n",
        "    l1 = tf.nn.max_pool(l1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
        "    #Sale imagen de 14*14*32\n",
        "    \n",
        "    #Segunda convolución\n",
        "    #Recibe imagen de #14*14*64\n",
        "    l2 = tf.nn.conv2d(l1, weights['W_conv2'], strides=[1,1,1,1], padding='SAME')\n",
        "    l2 = tf.add(l2, biases['b_conv2'])\n",
        "    l2 = tf.nn.relu(l2)\n",
        "    l2 = tf.nn.max_pool(l2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
        "    #Sale imagen de 7*7*64\n",
        "    #Tercer convolución\n",
        "    #Recibe imagen de #7*7*64\n",
        "    l3 = tf.nn.conv2d(l2,weights['W_conv3'], strides=[1,1,1,1], padding='SAME')\n",
        "    l3 = tf.add(l3,biases['b_conv3'])\n",
        "    l3 = tf.nn.relu(l3)\n",
        "    l3 = tf.nn.max_pool(l3, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
        "    #Sale imagen de 4*4*128\n",
        "    \n",
        "    fc = tf.reshape(l3,[-1, 4*4*128])\n",
        "    fc = tf.nn.relu(tf.matmul(fc, weights['W_fc'])+biases['b_fc'])\n",
        "    fc = tf.nn.dropout(fc, keep_rate)\n",
        "\n",
        "    output = tf.matmul(fc, weights['out'])+biases['out']\n",
        "\n",
        "    # Declarando la funcion de costo y entrenamiento\n",
        "    cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(logits=output\n",
        "                                                                   , labels=y) )\n",
        "    optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
        "\n",
        "    #Accuracy para está epoca\n",
        "    correct = tf.equal(tf.argmax(output, 1), tf.argmax(y, 1))\n",
        "    acc = tf.reduce_mean(tf.cast(correct, 'float'))\n",
        "    \n",
        "    return dict(\n",
        "              x=x,\n",
        "              y=y,\n",
        "              output=output,\n",
        "              cost=cost,\n",
        "              acc = acc,\n",
        "              optimizer=optimizer\n",
        "              )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VkLMpEfiN74Y",
        "outputId": "c7e83e93-c70a-44e3-df13-0c59df07f3e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "Neural_network_model()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'acc': <tf.Tensor 'Mean_3:0' shape=() dtype=float32>,\n",
              " 'cost': <tf.Tensor 'Mean_2:0' shape=() dtype=float32>,\n",
              " 'optimizer': <tf.Operation 'Adam_1' type=NoOp>,\n",
              " 'output': <tf.Tensor 'add_9:0' shape=(?, 10) dtype=float32>,\n",
              " 'x': <tf.Tensor 'Placeholder_2:0' shape=(?, 784) dtype=float32>,\n",
              " 'y': <tf.Tensor 'Placeholder_3:0' shape=<unknown> dtype=float32>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "16XCnCelN74d",
        "colab": {}
      },
      "source": [
        "loss = []\n",
        "accuracy = []\n",
        "def train_neural_network(DNN, hm_epochs=500,batch_size=100):\n",
        "    with tf.Session() as sess:\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "\n",
        "        for epoch in range(hm_epochs):\n",
        "            epoch_loss = 0\n",
        "            for _ in range(int(mnist.train.num_examples/batch_size)):\n",
        "                epoch_x, epoch_y = mnist.train.next_batch(batch_size)\n",
        "                feed_dict={DNN[\"x\"]: epoch_x, \n",
        "                           DNN[\"y\"]: epoch_y}\n",
        "                _, c, prediction,y,acc   = sess.run([DNN[\"optimizer\"], DNN[\"cost\"]\n",
        "                                                 , DNN[\"output\"], DNN[\"y\"],DNN[\"acc\"]], \n",
        "                                                feed_dict=feed_dict)\n",
        "                epoch_loss += c\n",
        "            loss.append(epoch_loss)\n",
        "            accuracy.append(acc)  \n",
        "            print('Epoch', epoch, 'completed out of',hm_epochs,'loss:',epoch_loss)\n",
        "\n",
        "        \n",
        "        prediction,y   = sess.run([DNN[\"output\"], DNN[\"y\"]], feed_dict={DNN[\"x\"]:mnist.test.images, DNN[\"y\"]:mnist.test.labels})\n",
        "        correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
        "        precision = tf.reduce_mean(tf.cast(correct, 'float'))\n",
        "        print('Accuracy Test:',precision.eval())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-FTq8xNnN74g",
        "outputId": "5d6d98b4-ca3a-4d6e-f891-677425471a8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "DNN=Neural_network_model()\n",
        "train_neural_network(DNN)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 completed out of 500 loss: 60792731.56518555\n",
            "Epoch 1 completed out of 500 loss: 7382337.762023926\n",
            "Epoch 2 completed out of 500 loss: 3657346.8894577026\n",
            "Epoch 3 completed out of 500 loss: 2300636.666937828\n",
            "Epoch 4 completed out of 500 loss: 1604711.8484134674\n",
            "Epoch 5 completed out of 500 loss: 1105735.3863019943\n",
            "Epoch 6 completed out of 500 loss: 916616.2168502808\n",
            "Epoch 7 completed out of 500 loss: 697705.6771125793\n",
            "Epoch 8 completed out of 500 loss: 536524.2637712955\n",
            "Epoch 9 completed out of 500 loss: 442884.74571049213\n",
            "Epoch 10 completed out of 500 loss: 380395.77197670937\n",
            "Epoch 11 completed out of 500 loss: 318568.84393009543\n",
            "Epoch 12 completed out of 500 loss: 261449.1266746521\n",
            "Epoch 13 completed out of 500 loss: 259150.48775342107\n",
            "Epoch 14 completed out of 500 loss: 254405.67350344776\n",
            "Epoch 15 completed out of 500 loss: 229027.9564459324\n",
            "Epoch 16 completed out of 500 loss: 174103.34266614914\n",
            "Epoch 17 completed out of 500 loss: 159788.520966053\n",
            "Epoch 18 completed out of 500 loss: 145315.65402245522\n",
            "Epoch 19 completed out of 500 loss: 140983.6951521635\n",
            "Epoch 20 completed out of 500 loss: 119576.0547838211\n",
            "Epoch 21 completed out of 500 loss: 112906.0046198368\n",
            "Epoch 22 completed out of 500 loss: 111471.5202448368\n",
            "Epoch 23 completed out of 500 loss: 92682.88752222061\n",
            "Epoch 24 completed out of 500 loss: 97138.52801576015\n",
            "Epoch 25 completed out of 500 loss: 93867.08764198422\n",
            "Epoch 26 completed out of 500 loss: 106566.75549316406\n",
            "Epoch 27 completed out of 500 loss: 70671.17609602213\n",
            "Epoch 28 completed out of 500 loss: 69248.02392148972\n",
            "Epoch 29 completed out of 500 loss: 89242.6492843628\n",
            "Epoch 30 completed out of 500 loss: 61513.18764209747\n",
            "Epoch 31 completed out of 500 loss: 66320.66083431244\n",
            "Epoch 32 completed out of 500 loss: 67030.67743778229\n",
            "Epoch 33 completed out of 500 loss: 66200.59149622917\n",
            "Epoch 34 completed out of 500 loss: 63737.75995725393\n",
            "Epoch 35 completed out of 500 loss: 54861.99589160085\n",
            "Epoch 36 completed out of 500 loss: 74526.05670851271\n",
            "Epoch 37 completed out of 500 loss: 43072.26004329324\n",
            "Epoch 38 completed out of 500 loss: 45753.614074110985\n",
            "Epoch 39 completed out of 500 loss: 38288.59658586979\n",
            "Epoch 40 completed out of 500 loss: 41633.73630452156\n",
            "Epoch 41 completed out of 500 loss: 55611.70659351349\n",
            "Epoch 42 completed out of 500 loss: 46008.92646694183\n",
            "Epoch 43 completed out of 500 loss: 55972.36884844303\n",
            "Epoch 44 completed out of 500 loss: 34434.41096019745\n",
            "Epoch 45 completed out of 500 loss: 41258.70153951645\n",
            "Epoch 46 completed out of 500 loss: 44705.226613521576\n",
            "Epoch 47 completed out of 500 loss: 33703.777430057526\n",
            "Epoch 48 completed out of 500 loss: 38813.38399064541\n",
            "Epoch 49 completed out of 500 loss: 34932.82924890518\n",
            "Epoch 50 completed out of 500 loss: 33820.752500116825\n",
            "Epoch 51 completed out of 500 loss: 32541.825647354126\n",
            "Epoch 52 completed out of 500 loss: 28258.2948346138\n",
            "Epoch 53 completed out of 500 loss: 32613.935955762863\n",
            "Epoch 54 completed out of 500 loss: 26093.786238908768\n",
            "Epoch 55 completed out of 500 loss: 25942.48937445879\n",
            "Epoch 56 completed out of 500 loss: 38699.41340279579\n",
            "Epoch 57 completed out of 500 loss: 22767.94952058792\n",
            "Epoch 58 completed out of 500 loss: 27922.553208112717\n",
            "Epoch 59 completed out of 500 loss: 31370.632036209106\n",
            "Epoch 60 completed out of 500 loss: 34431.69978129864\n",
            "Epoch 61 completed out of 500 loss: 23992.73618197441\n",
            "Epoch 62 completed out of 500 loss: 20701.82926249504\n",
            "Epoch 63 completed out of 500 loss: 28478.86950749159\n",
            "Epoch 64 completed out of 500 loss: 32878.86773109436\n",
            "Epoch 65 completed out of 500 loss: 25638.31169182062\n",
            "Epoch 66 completed out of 500 loss: 28005.01557636261\n",
            "Epoch 67 completed out of 500 loss: 19472.70506232977\n",
            "Epoch 68 completed out of 500 loss: 28569.646238327026\n",
            "Epoch 69 completed out of 500 loss: 26272.72767519951\n",
            "Epoch 70 completed out of 500 loss: 14663.339527130127\n",
            "Epoch 71 completed out of 500 loss: 20518.484853237867\n",
            "Epoch 72 completed out of 500 loss: 25611.198085308075\n",
            "Epoch 73 completed out of 500 loss: 22121.115036964417\n",
            "Epoch 74 completed out of 500 loss: 19966.91511774063\n",
            "Epoch 75 completed out of 500 loss: 17831.268705368042\n",
            "Epoch 76 completed out of 500 loss: 17817.111825942993\n",
            "Epoch 77 completed out of 500 loss: 21374.810193706304\n",
            "Epoch 78 completed out of 500 loss: 19081.614374160767\n",
            "Epoch 79 completed out of 500 loss: 20181.53378546238\n",
            "Epoch 80 completed out of 500 loss: 18710.865427970886\n",
            "Epoch 81 completed out of 500 loss: 13507.003750801086\n",
            "Epoch 82 completed out of 500 loss: 16437.255136489868\n",
            "Epoch 83 completed out of 500 loss: 18958.998348238467\n",
            "Epoch 84 completed out of 500 loss: 16673.41126060486\n",
            "Epoch 85 completed out of 500 loss: 18512.46849298477\n",
            "Epoch 86 completed out of 500 loss: 16312.40517616272\n",
            "Epoch 87 completed out of 500 loss: 24748.07175207138\n",
            "Epoch 88 completed out of 500 loss: 25988.85072517395\n",
            "Epoch 89 completed out of 500 loss: 15536.583950042725\n",
            "Epoch 90 completed out of 500 loss: 14198.024410486221\n",
            "Epoch 91 completed out of 500 loss: 18564.707701683044\n",
            "Epoch 92 completed out of 500 loss: 13558.784902334213\n",
            "Epoch 93 completed out of 500 loss: 20682.045528411865\n",
            "Epoch 94 completed out of 500 loss: 17344.129999160767\n",
            "Epoch 95 completed out of 500 loss: 11075.603271126747\n",
            "Epoch 96 completed out of 500 loss: 13541.143984556198\n",
            "Epoch 97 completed out of 500 loss: 9988.281047940254\n",
            "Epoch 98 completed out of 500 loss: 9791.186148643494\n",
            "Epoch 99 completed out of 500 loss: 11179.061269283295\n",
            "Epoch 100 completed out of 500 loss: 24455.537307739258\n",
            "Epoch 101 completed out of 500 loss: 19826.987913131714\n",
            "Epoch 102 completed out of 500 loss: 16125.689067602158\n",
            "Epoch 103 completed out of 500 loss: 10966.060854911804\n",
            "Epoch 104 completed out of 500 loss: 17626.457091331482\n",
            "Epoch 105 completed out of 500 loss: 16715.529406309128\n",
            "Epoch 106 completed out of 500 loss: 11433.449834823608\n",
            "Epoch 107 completed out of 500 loss: 11823.911093711853\n",
            "Epoch 108 completed out of 500 loss: 14803.597420215607\n",
            "Epoch 109 completed out of 500 loss: 16321.840970993042\n",
            "Epoch 110 completed out of 500 loss: 10954.977643966675\n",
            "Epoch 111 completed out of 500 loss: 14037.03709512949\n",
            "Epoch 112 completed out of 500 loss: 9789.509944915771\n",
            "Epoch 113 completed out of 500 loss: 15887.162086486816\n",
            "Epoch 114 completed out of 500 loss: 17657.31818664074\n",
            "Epoch 115 completed out of 500 loss: 12687.160872220993\n",
            "Epoch 116 completed out of 500 loss: 12708.57341003418\n",
            "Epoch 117 completed out of 500 loss: 11329.847271740437\n",
            "Epoch 118 completed out of 500 loss: 5006.548795700073\n",
            "Epoch 119 completed out of 500 loss: 9046.564038276672\n",
            "Epoch 120 completed out of 500 loss: 12584.561256408691\n",
            "Epoch 121 completed out of 500 loss: 26224.049518585205\n",
            "Epoch 122 completed out of 500 loss: 10136.711443424225\n",
            "Epoch 123 completed out of 500 loss: 6821.13606262207\n",
            "Epoch 124 completed out of 500 loss: 12527.522577285767\n",
            "Epoch 125 completed out of 500 loss: 15353.161432385445\n",
            "Epoch 126 completed out of 500 loss: 9690.911095142365\n",
            "Epoch 127 completed out of 500 loss: 15516.899448394775\n",
            "Epoch 128 completed out of 500 loss: 6808.17777633667\n",
            "Epoch 129 completed out of 500 loss: 11897.591473571956\n",
            "Epoch 130 completed out of 500 loss: 13174.648594834842\n",
            "Epoch 131 completed out of 500 loss: 10855.890761852264\n",
            "Epoch 132 completed out of 500 loss: 13057.356001853943\n",
            "Epoch 133 completed out of 500 loss: 12633.497646331787\n",
            "Epoch 134 completed out of 500 loss: 12293.284798920155\n",
            "Epoch 135 completed out of 500 loss: 9905.080173492432\n",
            "Epoch 136 completed out of 500 loss: 11569.7271630764\n",
            "Epoch 137 completed out of 500 loss: 11348.87709236145\n",
            "Epoch 138 completed out of 500 loss: 12932.45386505127\n",
            "Epoch 139 completed out of 500 loss: 6892.860782623291\n",
            "Epoch 140 completed out of 500 loss: 6546.099632263184\n",
            "Epoch 141 completed out of 500 loss: 8277.276611804962\n",
            "Epoch 142 completed out of 500 loss: 13931.78603553772\n",
            "Epoch 143 completed out of 500 loss: 12308.589550495148\n",
            "Epoch 144 completed out of 500 loss: 9285.498710632324\n",
            "Epoch 145 completed out of 500 loss: 13508.743064880371\n",
            "Epoch 146 completed out of 500 loss: 9618.815601348877\n",
            "Epoch 147 completed out of 500 loss: 9615.766240119934\n",
            "Epoch 148 completed out of 500 loss: 5027.141511917114\n",
            "Epoch 149 completed out of 500 loss: 5152.695046424866\n",
            "Epoch 150 completed out of 500 loss: 10154.388507843018\n",
            "Epoch 151 completed out of 500 loss: 7732.638565897942\n",
            "Epoch 152 completed out of 500 loss: 11971.184830188751\n",
            "Epoch 153 completed out of 500 loss: 13854.0763463974\n",
            "Epoch 154 completed out of 500 loss: 7484.613380432129\n",
            "Epoch 155 completed out of 500 loss: 13940.15608215332\n",
            "Epoch 156 completed out of 500 loss: 10084.634760379791\n",
            "Epoch 157 completed out of 500 loss: 10432.40309265256\n",
            "Epoch 158 completed out of 500 loss: 8633.325477600098\n",
            "Epoch 159 completed out of 500 loss: 5025.927680969238\n",
            "Epoch 160 completed out of 500 loss: 6216.6067237854\n",
            "Epoch 161 completed out of 500 loss: 13945.628448367119\n",
            "Epoch 162 completed out of 500 loss: 11885.31097126007\n",
            "Epoch 163 completed out of 500 loss: 11252.353260040283\n",
            "Epoch 164 completed out of 500 loss: 6550.060939788818\n",
            "Epoch 165 completed out of 500 loss: 8271.745457649231\n",
            "Epoch 166 completed out of 500 loss: 8854.449293136597\n",
            "Epoch 167 completed out of 500 loss: 13706.881595611572\n",
            "Epoch 168 completed out of 500 loss: 10173.69200702096\n",
            "Epoch 169 completed out of 500 loss: 6319.810466766357\n",
            "Epoch 170 completed out of 500 loss: 4948.548179864883\n",
            "Epoch 171 completed out of 500 loss: 8121.661653518677\n",
            "Epoch 172 completed out of 500 loss: 5721.099461734295\n",
            "Epoch 173 completed out of 500 loss: 5532.728477478027\n",
            "Epoch 174 completed out of 500 loss: 10142.580814361572\n",
            "Epoch 175 completed out of 500 loss: 7731.009986877441\n",
            "Epoch 176 completed out of 500 loss: 10553.895195007324\n",
            "Epoch 177 completed out of 500 loss: 9545.142698764801\n",
            "Epoch 178 completed out of 500 loss: 6859.194173812866\n",
            "Epoch 179 completed out of 500 loss: 6036.551704406738\n",
            "Epoch 180 completed out of 500 loss: 10771.053531646729\n",
            "Epoch 181 completed out of 500 loss: 3793.1843910217285\n",
            "Epoch 182 completed out of 500 loss: 13600.126670837402\n",
            "Epoch 183 completed out of 500 loss: 11767.615816116333\n",
            "Epoch 184 completed out of 500 loss: 5560.392185211182\n",
            "Epoch 185 completed out of 500 loss: 5680.772831916809\n",
            "Epoch 186 completed out of 500 loss: 7203.523399353027\n",
            "Epoch 187 completed out of 500 loss: 5392.475748062134\n",
            "Epoch 188 completed out of 500 loss: 11708.902746200562\n",
            "Epoch 189 completed out of 500 loss: 11445.853583455086\n",
            "Epoch 190 completed out of 500 loss: 4388.959022521973\n",
            "Epoch 191 completed out of 500 loss: 2655.965644836426\n",
            "Epoch 192 completed out of 500 loss: 3456.6314086914062\n",
            "Epoch 193 completed out of 500 loss: 5321.084674835205\n",
            "Epoch 194 completed out of 500 loss: 9480.535140991211\n",
            "Epoch 195 completed out of 500 loss: 11996.249254703522\n",
            "Epoch 196 completed out of 500 loss: 9479.52644109726\n",
            "Epoch 197 completed out of 500 loss: 5279.598239898682\n",
            "Epoch 198 completed out of 500 loss: 6542.799987792969\n",
            "Epoch 199 completed out of 500 loss: 11151.674711227417\n",
            "Epoch 200 completed out of 500 loss: 7294.277256011963\n",
            "Epoch 201 completed out of 500 loss: 6626.631013870239\n",
            "Epoch 202 completed out of 500 loss: 7031.917724609375\n",
            "Epoch 203 completed out of 500 loss: 7130.052880093455\n",
            "Epoch 204 completed out of 500 loss: 7268.71325302124\n",
            "Epoch 205 completed out of 500 loss: 8385.852840423584\n",
            "Epoch 206 completed out of 500 loss: 3374.5215454101562\n",
            "Epoch 207 completed out of 500 loss: 5049.441020965576\n",
            "Epoch 208 completed out of 500 loss: 7344.6747552752495\n",
            "Epoch 209 completed out of 500 loss: 9272.946067333221\n",
            "Epoch 210 completed out of 500 loss: 5986.717796087265\n",
            "Epoch 211 completed out of 500 loss: 9172.039358854294\n",
            "Epoch 212 completed out of 500 loss: 6382.844520568848\n",
            "Epoch 213 completed out of 500 loss: 4564.422622680664\n",
            "Epoch 214 completed out of 500 loss: 9113.847011327744\n",
            "Epoch 215 completed out of 500 loss: 7403.530326843262\n",
            "Epoch 216 completed out of 500 loss: 11288.203508377075\n",
            "Epoch 217 completed out of 500 loss: 5484.826102733612\n",
            "Epoch 218 completed out of 500 loss: 4055.4335284233093\n",
            "Epoch 219 completed out of 500 loss: 9737.015829086304\n",
            "Epoch 220 completed out of 500 loss: 3555.157102584839\n",
            "Epoch 221 completed out of 500 loss: 5036.464170455933\n",
            "Epoch 222 completed out of 500 loss: 8322.259588241577\n",
            "Epoch 223 completed out of 500 loss: 8284.862087249756\n",
            "Epoch 224 completed out of 500 loss: 10368.230918884277\n",
            "Epoch 225 completed out of 500 loss: 5505.035797119141\n",
            "Epoch 226 completed out of 500 loss: 4066.3427743911743\n",
            "Epoch 227 completed out of 500 loss: 7507.566299438477\n",
            "Epoch 228 completed out of 500 loss: 7705.006553649902\n",
            "Epoch 229 completed out of 500 loss: 8047.802440643311\n",
            "Epoch 230 completed out of 500 loss: 4272.768732070923\n",
            "Epoch 231 completed out of 500 loss: 2414.7406435012817\n",
            "Epoch 232 completed out of 500 loss: 11990.864532470703\n",
            "Epoch 233 completed out of 500 loss: 8830.123149871826\n",
            "Epoch 234 completed out of 500 loss: 6136.065450668335\n",
            "Epoch 235 completed out of 500 loss: 8706.16812992096\n",
            "Epoch 236 completed out of 500 loss: 2508.8489475250244\n",
            "Epoch 237 completed out of 500 loss: 8089.66400718689\n",
            "Epoch 238 completed out of 500 loss: 7190.08424949646\n",
            "Epoch 239 completed out of 500 loss: 6063.012676239014\n",
            "Epoch 240 completed out of 500 loss: 6860.55065536499\n",
            "Epoch 241 completed out of 500 loss: 4219.22519493103\n",
            "Epoch 242 completed out of 500 loss: 5112.307323377579\n",
            "Epoch 243 completed out of 500 loss: 5914.53161239624\n",
            "Epoch 244 completed out of 500 loss: 8839.102645874023\n",
            "Epoch 245 completed out of 500 loss: 6361.810542345047\n",
            "Epoch 246 completed out of 500 loss: 9880.292739868164\n",
            "Epoch 247 completed out of 500 loss: 9376.565410614014\n",
            "Epoch 248 completed out of 500 loss: 6321.695640563965\n",
            "Epoch 249 completed out of 500 loss: 1838.1953010559082\n",
            "Epoch 250 completed out of 500 loss: 4113.917230606079\n",
            "Epoch 251 completed out of 500 loss: 6910.858357429504\n",
            "Epoch 252 completed out of 500 loss: 4453.758632659912\n",
            "Epoch 253 completed out of 500 loss: 7966.058880805969\n",
            "Epoch 254 completed out of 500 loss: 1545.7064361572266\n",
            "Epoch 255 completed out of 500 loss: 5825.961574316025\n",
            "Epoch 256 completed out of 500 loss: 6559.8418045043945\n",
            "Epoch 257 completed out of 500 loss: 6966.840919494629\n",
            "Epoch 258 completed out of 500 loss: 4338.3154373168945\n",
            "Epoch 259 completed out of 500 loss: 7585.130928039551\n",
            "Epoch 260 completed out of 500 loss: 8155.381886482239\n",
            "Epoch 261 completed out of 500 loss: 9743.162472724915\n",
            "Epoch 262 completed out of 500 loss: 4644.080822944641\n",
            "Epoch 263 completed out of 500 loss: 9544.908774107695\n",
            "Epoch 264 completed out of 500 loss: 6796.892143249512\n",
            "Epoch 265 completed out of 500 loss: 2572.356246948242\n",
            "Epoch 266 completed out of 500 loss: 8508.660753250122\n",
            "Epoch 267 completed out of 500 loss: 4977.039192199707\n",
            "Epoch 268 completed out of 500 loss: 4109.561304092407\n",
            "Epoch 269 completed out of 500 loss: 16206.317091464996\n",
            "Epoch 270 completed out of 500 loss: 7326.729602813721\n",
            "Epoch 271 completed out of 500 loss: 2275.0427169799805\n",
            "Epoch 272 completed out of 500 loss: 5090.26171875\n",
            "Epoch 273 completed out of 500 loss: 3732.095965385437\n",
            "Epoch 274 completed out of 500 loss: 2863.7929916381836\n",
            "Epoch 275 completed out of 500 loss: 7319.954770088196\n",
            "Epoch 276 completed out of 500 loss: 2789.0487022399902\n",
            "Epoch 277 completed out of 500 loss: 5263.415668487549\n",
            "Epoch 278 completed out of 500 loss: 10735.933795928955\n",
            "Epoch 279 completed out of 500 loss: 4876.69499540329\n",
            "Epoch 280 completed out of 500 loss: 6992.501237869263\n",
            "Epoch 281 completed out of 500 loss: 4424.593434333801\n",
            "Epoch 282 completed out of 500 loss: 7398.87956237793\n",
            "Epoch 283 completed out of 500 loss: 2184.7373275756836\n",
            "Epoch 284 completed out of 500 loss: 7946.4549560546875\n",
            "Epoch 285 completed out of 500 loss: 7942.027131080627\n",
            "Epoch 286 completed out of 500 loss: 7789.671257019043\n",
            "Epoch 287 completed out of 500 loss: 6303.917177200317\n",
            "Epoch 288 completed out of 500 loss: 3262.274797439575\n",
            "Epoch 289 completed out of 500 loss: 10656.085510253906\n",
            "Epoch 290 completed out of 500 loss: 6347.968075275421\n",
            "Epoch 291 completed out of 500 loss: 4932.178253173828\n",
            "Epoch 292 completed out of 500 loss: 8217.86962890625\n",
            "Epoch 293 completed out of 500 loss: 9345.11716079712\n",
            "Epoch 294 completed out of 500 loss: 5661.446678638458\n",
            "Epoch 295 completed out of 500 loss: 7221.72961473465\n",
            "Epoch 296 completed out of 500 loss: 2170.3692016601562\n",
            "Epoch 297 completed out of 500 loss: 4530.654388427734\n",
            "Epoch 298 completed out of 500 loss: 3475.004066467285\n",
            "Epoch 299 completed out of 500 loss: 3820.05952835083\n",
            "Epoch 300 completed out of 500 loss: 6462.440267562866\n",
            "Epoch 301 completed out of 500 loss: 2520.367669582367\n",
            "Epoch 302 completed out of 500 loss: 4166.300631523132\n",
            "Epoch 303 completed out of 500 loss: 5566.82618355751\n",
            "Epoch 304 completed out of 500 loss: 4785.344217300415\n",
            "Epoch 305 completed out of 500 loss: 2892.114082336426\n",
            "Epoch 306 completed out of 500 loss: 6040.765829086304\n",
            "Epoch 307 completed out of 500 loss: 4815.139091491699\n",
            "Epoch 308 completed out of 500 loss: 7173.6179366111755\n",
            "Epoch 309 completed out of 500 loss: 14267.50706243515\n",
            "Epoch 310 completed out of 500 loss: 3982.0205993652344\n",
            "Epoch 311 completed out of 500 loss: 1681.843734741211\n",
            "Epoch 312 completed out of 500 loss: 2262.3455963134766\n",
            "Epoch 313 completed out of 500 loss: 6101.362266540527\n",
            "Epoch 314 completed out of 500 loss: 4131.7681714866085\n",
            "Epoch 315 completed out of 500 loss: 8498.694231033325\n",
            "Epoch 316 completed out of 500 loss: 1542.5426330566406\n",
            "Epoch 317 completed out of 500 loss: 500.91891384124756\n",
            "Epoch 318 completed out of 500 loss: 3728.4219856262207\n",
            "Epoch 319 completed out of 500 loss: 6443.402648925781\n",
            "Epoch 320 completed out of 500 loss: 4251.159076690674\n",
            "Epoch 321 completed out of 500 loss: 7503.764035224915\n",
            "Epoch 322 completed out of 500 loss: 4670.9553565979\n",
            "Epoch 323 completed out of 500 loss: 6317.574733734131\n",
            "Epoch 324 completed out of 500 loss: 7791.149543762207\n",
            "Epoch 325 completed out of 500 loss: 8489.194365978241\n",
            "Epoch 326 completed out of 500 loss: 2592.182014465332\n",
            "Epoch 327 completed out of 500 loss: 6617.37805557251\n",
            "Epoch 328 completed out of 500 loss: 4540.147079467773\n",
            "Epoch 329 completed out of 500 loss: 5290.445083618164\n",
            "Epoch 330 completed out of 500 loss: 6365.698303222656\n",
            "Epoch 331 completed out of 500 loss: 5368.438247680664\n",
            "Epoch 332 completed out of 500 loss: 4617.28616809845\n",
            "Epoch 333 completed out of 500 loss: 5074.796711444855\n",
            "Epoch 334 completed out of 500 loss: 9566.430445671082\n",
            "Epoch 335 completed out of 500 loss: 5712.1187953948975\n",
            "Epoch 336 completed out of 500 loss: 1615.7443885803223\n",
            "Epoch 337 completed out of 500 loss: 2161.701904296875\n",
            "Epoch 338 completed out of 500 loss: 3458.757209777832\n",
            "Epoch 339 completed out of 500 loss: 6673.5002546310425\n",
            "Epoch 340 completed out of 500 loss: 7236.874462127686\n",
            "Epoch 341 completed out of 500 loss: 7337.938220977783\n",
            "Epoch 342 completed out of 500 loss: 675.300609588623\n",
            "Epoch 343 completed out of 500 loss: 9.001250267028809\n",
            "Epoch 344 completed out of 500 loss: 9930.148197174072\n",
            "Epoch 345 completed out of 500 loss: 2234.0471954345703\n",
            "Epoch 346 completed out of 500 loss: 6977.806873321533\n",
            "Epoch 347 completed out of 500 loss: 5690.164405822754\n",
            "Epoch 348 completed out of 500 loss: 5751.127058029175\n",
            "Epoch 349 completed out of 500 loss: 6432.994210243225\n",
            "Epoch 350 completed out of 500 loss: 2159.133087158203\n",
            "Epoch 351 completed out of 500 loss: 6285.661541938782\n",
            "Epoch 352 completed out of 500 loss: 6236.572250366211\n",
            "Epoch 353 completed out of 500 loss: 2532.4679374694824\n",
            "Epoch 354 completed out of 500 loss: 5702.678178787231\n",
            "Epoch 355 completed out of 500 loss: 7593.540557861328\n",
            "Epoch 356 completed out of 500 loss: 2114.2905254364014\n",
            "Epoch 357 completed out of 500 loss: 1420.6638946533203\n",
            "Epoch 358 completed out of 500 loss: 3915.0240364074707\n",
            "Epoch 359 completed out of 500 loss: 6426.373081207275\n",
            "Epoch 360 completed out of 500 loss: 4254.047187805176\n",
            "Epoch 361 completed out of 500 loss: 5288.090337753296\n",
            "Epoch 362 completed out of 500 loss: 4717.776531219482\n",
            "Epoch 363 completed out of 500 loss: 6871.5337924957275\n",
            "Epoch 364 completed out of 500 loss: 6270.614687919617\n",
            "Epoch 365 completed out of 500 loss: 7435.761981964111\n",
            "Epoch 366 completed out of 500 loss: 1895.5626602172852\n",
            "Epoch 367 completed out of 500 loss: 7109.755565643311\n",
            "Epoch 368 completed out of 500 loss: 2358.840286254883\n",
            "Epoch 369 completed out of 500 loss: 4319.810699462891\n",
            "Epoch 370 completed out of 500 loss: 2550.448269367218\n",
            "Epoch 371 completed out of 500 loss: 1613.2199722528458\n",
            "Epoch 372 completed out of 500 loss: 3424.7807817459106\n",
            "Epoch 373 completed out of 500 loss: 2005.1264207363129\n",
            "Epoch 374 completed out of 500 loss: 3627.764748811722\n",
            "Epoch 375 completed out of 500 loss: 1392.3856048583984\n",
            "Epoch 376 completed out of 500 loss: 4859.541526794434\n",
            "Epoch 377 completed out of 500 loss: 7906.724315643311\n",
            "Epoch 378 completed out of 500 loss: 1828.3278121948242\n",
            "Epoch 379 completed out of 500 loss: 2272.0959548950195\n",
            "Epoch 380 completed out of 500 loss: 4176.763591766357\n",
            "Epoch 381 completed out of 500 loss: 3551.30948638916\n",
            "Epoch 382 completed out of 500 loss: 2809.236219882965\n",
            "Epoch 383 completed out of 500 loss: 4112.906902313232\n",
            "Epoch 384 completed out of 500 loss: 2835.955461502075\n",
            "Epoch 385 completed out of 500 loss: 7362.33317565918\n",
            "Epoch 386 completed out of 500 loss: 5111.017311096191\n",
            "Epoch 387 completed out of 500 loss: 3983.753433227539\n",
            "Epoch 388 completed out of 500 loss: 2471.8610877990723\n",
            "Epoch 389 completed out of 500 loss: 4028.6073303222656\n",
            "Epoch 390 completed out of 500 loss: 3433.0629410743713\n",
            "Epoch 391 completed out of 500 loss: 5390.031379699707\n",
            "Epoch 392 completed out of 500 loss: 5676.411249160767\n",
            "Epoch 393 completed out of 500 loss: 4759.799348831177\n",
            "Epoch 394 completed out of 500 loss: 4618.697367668152\n",
            "Epoch 395 completed out of 500 loss: 2918.654098510742\n",
            "Epoch 396 completed out of 500 loss: 2569.3984146118164\n",
            "Epoch 397 completed out of 500 loss: 2726.5085678100586\n",
            "Epoch 398 completed out of 500 loss: 5061.870074272156\n",
            "Epoch 399 completed out of 500 loss: 1303.9053135812283\n",
            "Epoch 400 completed out of 500 loss: 1272.7535934448242\n",
            "Epoch 401 completed out of 500 loss: 6581.879509449005\n",
            "Epoch 402 completed out of 500 loss: 5213.112717628479\n",
            "Epoch 403 completed out of 500 loss: 6609.086424589157\n",
            "Epoch 404 completed out of 500 loss: 2366.4427032470703\n",
            "Epoch 405 completed out of 500 loss: 7107.597067832947\n",
            "Epoch 406 completed out of 500 loss: 1822.3633117675781\n",
            "Epoch 407 completed out of 500 loss: 2293.6421699523926\n",
            "Epoch 408 completed out of 500 loss: 3860.036735534668\n",
            "Epoch 409 completed out of 500 loss: 2624.816022872925\n",
            "Epoch 410 completed out of 500 loss: 2060.5195236206055\n",
            "Epoch 411 completed out of 500 loss: 4117.050941884518\n",
            "Epoch 412 completed out of 500 loss: 3174.339065551758\n",
            "Epoch 413 completed out of 500 loss: 0.0\n",
            "Epoch 414 completed out of 500 loss: 7883.214522123337\n",
            "Epoch 415 completed out of 500 loss: 4230.029365539551\n",
            "Epoch 416 completed out of 500 loss: 4760.019374847412\n",
            "Epoch 417 completed out of 500 loss: 8138.257116317749\n",
            "Epoch 418 completed out of 500 loss: 3418.2200756073\n",
            "Epoch 419 completed out of 500 loss: 1694.1142654418945\n",
            "Epoch 420 completed out of 500 loss: 1796.2685852050781\n",
            "Epoch 421 completed out of 500 loss: 6523.909805297852\n",
            "Epoch 422 completed out of 500 loss: 1006.9062557220459\n",
            "Epoch 423 completed out of 500 loss: 1778.04809486866\n",
            "Epoch 424 completed out of 500 loss: 4556.983191490173\n",
            "Epoch 425 completed out of 500 loss: 4186.137532234192\n",
            "Epoch 426 completed out of 500 loss: 14009.531791687012\n",
            "Epoch 427 completed out of 500 loss: 5138.582824707031\n",
            "Epoch 428 completed out of 500 loss: 1339.3159523010254\n",
            "Epoch 429 completed out of 500 loss: 2369.6742312908173\n",
            "Epoch 430 completed out of 500 loss: 2714.7196197509766\n",
            "Epoch 431 completed out of 500 loss: 3766.534957885742\n",
            "Epoch 432 completed out of 500 loss: 8146.466935873032\n",
            "Epoch 433 completed out of 500 loss: 6372.754676818848\n",
            "Epoch 434 completed out of 500 loss: 3840.9238662719727\n",
            "Epoch 435 completed out of 500 loss: 2590.749801635742\n",
            "Epoch 436 completed out of 500 loss: 1694.635971069336\n",
            "Epoch 437 completed out of 500 loss: 7919.3811111450195\n",
            "Epoch 438 completed out of 500 loss: 2361.6168699264526\n",
            "Epoch 439 completed out of 500 loss: 3169.762176513672\n",
            "Epoch 440 completed out of 500 loss: 2140.5536193847656\n",
            "Epoch 441 completed out of 500 loss: 10657.455261230469\n",
            "Epoch 442 completed out of 500 loss: 2078.7861518859863\n",
            "Epoch 443 completed out of 500 loss: 2978.050361633301\n",
            "Epoch 444 completed out of 500 loss: 4407.717811584473\n",
            "Epoch 445 completed out of 500 loss: 1893.6845264434814\n",
            "Epoch 446 completed out of 500 loss: 4115.257949829102\n",
            "Epoch 447 completed out of 500 loss: 4291.244396209717\n",
            "Epoch 448 completed out of 500 loss: 4855.626468658447\n",
            "Epoch 449 completed out of 500 loss: 1409.8392539024353\n",
            "Epoch 450 completed out of 500 loss: 5703.342590332031\n",
            "Epoch 451 completed out of 500 loss: 1589.871545791626\n",
            "Epoch 452 completed out of 500 loss: 5068.222267150879\n",
            "Epoch 453 completed out of 500 loss: 554.5231323242188\n",
            "Epoch 454 completed out of 500 loss: 3689.8311920166016\n",
            "Epoch 455 completed out of 500 loss: 5262.463893890381\n",
            "Epoch 456 completed out of 500 loss: 5228.5866355896\n",
            "Epoch 457 completed out of 500 loss: 2025.8743646144867\n",
            "Epoch 458 completed out of 500 loss: 6507.800463676453\n",
            "Epoch 459 completed out of 500 loss: 5952.950004577637\n",
            "Epoch 460 completed out of 500 loss: 7417.56237411499\n",
            "Epoch 461 completed out of 500 loss: 5495.296703338623\n",
            "Epoch 462 completed out of 500 loss: 6251.735381126404\n",
            "Epoch 463 completed out of 500 loss: 1002.2226371765137\n",
            "Epoch 464 completed out of 500 loss: 1513.1714057922363\n",
            "Epoch 465 completed out of 500 loss: 5597.92991065979\n",
            "Epoch 466 completed out of 500 loss: 2379.8576974868774\n",
            "Epoch 467 completed out of 500 loss: 2135.7845573425293\n",
            "Epoch 468 completed out of 500 loss: 1383.1910400390625\n",
            "Epoch 469 completed out of 500 loss: 1486.7319030761719\n",
            "Epoch 470 completed out of 500 loss: 4301.452768325806\n",
            "Epoch 471 completed out of 500 loss: 5746.976308822632\n",
            "Epoch 472 completed out of 500 loss: 3226.585292816162\n",
            "Epoch 473 completed out of 500 loss: 8204.320242881775\n",
            "Epoch 474 completed out of 500 loss: 3430.5455017089844\n",
            "Epoch 475 completed out of 500 loss: 6198.551422119141\n",
            "Epoch 476 completed out of 500 loss: 1931.946029663086\n",
            "Epoch 477 completed out of 500 loss: 95.79219055175781\n",
            "Epoch 478 completed out of 500 loss: 1375.5245361328125\n",
            "Epoch 479 completed out of 500 loss: 4384.330375671387\n",
            "Epoch 480 completed out of 500 loss: 7781.941680908203\n",
            "Epoch 481 completed out of 500 loss: 4176.857791900635\n",
            "Epoch 482 completed out of 500 loss: 701.0321807861328\n",
            "Epoch 483 completed out of 500 loss: 1506.8584651947021\n",
            "Epoch 484 completed out of 500 loss: 2803.5036010742188\n",
            "Epoch 485 completed out of 500 loss: 4950.141412734985\n",
            "Epoch 486 completed out of 500 loss: 7746.113372802734\n",
            "Epoch 487 completed out of 500 loss: 962.7290496826172\n",
            "Epoch 488 completed out of 500 loss: 1005.7665557861328\n",
            "Epoch 489 completed out of 500 loss: 6203.49130153656\n",
            "Epoch 490 completed out of 500 loss: 4652.329254150391\n",
            "Epoch 491 completed out of 500 loss: 4770.02449798584\n",
            "Epoch 492 completed out of 500 loss: 2842.6748843193054\n",
            "Epoch 493 completed out of 500 loss: 1779.8799667358398\n",
            "Epoch 494 completed out of 500 loss: 5838.537446975708\n",
            "Epoch 495 completed out of 500 loss: 3166.645309448242\n",
            "Epoch 496 completed out of 500 loss: 3136.1243743896484\n",
            "Epoch 497 completed out of 500 loss: 809.6068840026855\n",
            "Epoch 498 completed out of 500 loss: 3906.882152557373\n",
            "Epoch 499 completed out of 500 loss: 5012.188045501709\n",
            "Accuracy Test: 0.9925\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwEg2euboJJD",
        "colab_type": "text"
      },
      "source": [
        "#Grafica de error#"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10RoGBuKoOPl",
        "colab_type": "code",
        "outputId": "6ae25b20-05ab-443c-da71-269bab0d8744",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "# Graph error\n",
        "def graph_error(err_vector):\n",
        "\n",
        "    plt.figure(0)\n",
        "    plt.plot(err_vector)\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Error')\n",
        "    plt.title('Loss Neural Network')\n",
        "    plt.show()\n",
        "    \n",
        "#Graph accuracy\n",
        "def graph_accuracy(accuracy):\n",
        "    plt.figure(0)\n",
        "    plt.plot(accuracy)\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Accuracy Neural Network')\n",
        "    plt.show()\n",
        "\n",
        "graph_error(loss)\n",
        "graph_accuracy(accuracy)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEWCAYAAABsY4yMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwJuZZcoBb2aWKQe8mVmmHPBmZpn6/7vLhmDMWhMjAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAk3k4y5UIzcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}