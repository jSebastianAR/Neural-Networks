{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jzgrhD_wt_K-",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# Author: Dr. Fernando Arce Vega                             #\n",
    "# Date: 09/06/2019                                           #\n",
    "##############################################################\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Sigmoid function\n",
    "def sigmoid(x):\n",
    "    \n",
    "    sig = 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    return(sig)\n",
    "\n",
    "# Feed forward\n",
    "def feed_forward(x, network):\n",
    "    \n",
    "    n_layers = network[4]+1 #number of hidden layers plus the output layer\n",
    "    outputD = {}\n",
    "    \"\"\"\n",
    "    print(\"============================FEEDFORWARD============================\")\n",
    "    print(\"=====================input {}=====================\".format(x))\n",
    "    print(\"Weights {}\".format(network[0]))\n",
    "    print(\"Bias {}\".format(network[1]))\n",
    "    print(\"Output {}\".format(outputD))\n",
    "    \"\"\"\n",
    "    for i in range(n_layers):\n",
    "      \n",
    "      if i==0: #if its the first layer\n",
    "        #print('Capa {}'.format(i))\n",
    "        dotproduct = np.matmul(x,network[0]['W_hl'+str(i)].transpose()) + network[1]['b_hl'+str(i)] #does dot product\n",
    "        output = sigmoid(dotproduct) #\n",
    "        #print(output)\n",
    "        #print(output.shape)\n",
    "        #print(output.transpose().shape)\n",
    "        outputD['output_hl'+str(i)]=output #stores the output of each layer hidden layer\n",
    "      elif i==n_layers-1: #if it is the last layer\n",
    "        #print('Capa {}'.format(i))\n",
    "        dotproduct = np.matmul(outputD['output_hl'+str(i-1)],network[0]['W_out'].transpose()) + network[1]['b_out'] #does dot product\n",
    "        output = sigmoid(dotproduct) #\n",
    "        #print(output)\n",
    "        #print(output.shape)\n",
    "        #print(output.transpose().shape)\n",
    "        outputD['output_out']=output #stores the output of output layer\n",
    "      else: #if its any other hidden layer\n",
    "        #print('Capa {}'.format(i))\n",
    "        dotproduct = np.matmul(outputD['output_hl'+str(i-1)],network[0]['W_hl'+str(i)].transpose()) + network[1]['b_hl'+str(i)] #does dot product\n",
    "        output = sigmoid(dotproduct) #\n",
    "        #print(output)\n",
    "        #print(output.shape)\n",
    "        #print(output.transpose().shape)\n",
    "        outputD['output_hl'+str(i)]=output #stores the output of each layer hidden layer                       \n",
    "      \n",
    "      #print(\"Output {}\".format(outputD))\n",
    "    #print(\"============================FEEDFORWARD============================\")\n",
    "    \n",
    "    return outputD\n",
    "\n",
    "# Network error\n",
    "def net_error(tar, out):\n",
    "    \n",
    "    #print(\"tar:{} out:{}\".format(tar,out))\n",
    "    err = 0.5 * np.power(tar - out, 2)\n",
    "    \n",
    "    return(err)\n",
    "\n",
    "def outputLayer_Error(tar,network):\n",
    "  \n",
    "    #print(\"tar:{} net:{}\".format(tar,network[2]['output_out']))\n",
    "    #return -(tar - network[2]['output_out']) * network[2]['output_out'] * (1 - network[2]['output_out'])\n",
    "    derivate = network[2]['output_out'] * (1-network[2]['output_out'])\n",
    "    #print(derivate)\n",
    "    diff = -(tar - network[2]['output_out'])\n",
    "    #print(diff)\n",
    "    return np.multiply(diff,derivate)\n",
    "    \n",
    "  \n",
    "# Back-propagation\n",
    "def BP(x, tar, network):\n",
    "  \n",
    "  \n",
    "    \"\"\"\n",
    "    network[0]: weights\n",
    "    network[1]: biases\n",
    "    network[2]: outputs\n",
    "    network[3]: error layer\n",
    "    network[4]: n_hidden_layers\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    n_layers = network[4]+1 #number of hidden layers plus the output layer\n",
    "\n",
    "    #Calculating errors of each layer\n",
    "    for i in reversed(range(n_layers)):\n",
    "      if i==n_layers-1: #if its the output layer\n",
    "        # Output layer error (L)\n",
    "        L_error = outputLayer_Error(tar,network)\n",
    "        network[3]['e_output'] = L_error\n",
    "      elif i==n_layers-2: #if its the last hidden layer before output layer\n",
    "        if network[3]['e_output'].size!=1: #if its not only one neuron\n",
    "          dotproduct = np.matmul(network[3]['e_output'],network[0]['W_out']) \n",
    "          l_error = dotproduct * network[2]['output_hl'+str(i)] * (1 - network[2]['output_hl'+str(i)])\n",
    "          network[3]['e_hl'+str(i)] = l_error #stores the error of the i-hidden-layer  \n",
    "        else:\n",
    "          l_error = (network[3]['e_output'] * network[0]['W_out']) * (network[2]['output_hl'+str(i)] * (1 - network[2]['output_hl'+str(i)]))\n",
    "          network[3]['e_hl'+str(i)] = l_error #stores the error of the i-hidden-layer  \n",
    "      else:\n",
    "        if network[3]['e_hl'+str(i+1)].size!=1:\n",
    "          dotproduct = np.matmul(network[3]['e_hl'+str(i+1)],network[0]['W_hl'+str(i+1)]) \n",
    "          l_error = dotproduct * (network[2]['output_hl'+str(i)] * (1 - network[2]['output_hl'+str(i)]))\n",
    "          network[3]['e_hl'+str(i)] = l_error #stores the error of the i-hidden-layer\n",
    "        else:\n",
    "          l_error = (network[3]['e_hl'+str(i+1)] * network[0]['W_hl'+str(i+1)]) * (network[2]['output_hl'+str(i)] * (1 - network[2]['output_hl'+str(i)]))\n",
    "          network[3]['e_hl'+str(i)] = l_error #stores the error of the i-hidden-layer\n",
    "              \n",
    "    #print(\"Error {}\".format(network[3]))\n",
    "          \n",
    "    #Calculating new weights and bias\n",
    "    n_Weights = {}\n",
    "    n_Bias = {}\n",
    "    \n",
    "    #print(network)\n",
    "    for i in reversed(range(n_layers)):\n",
    "      if i==n_layers-1:\n",
    "        \"\"\"\n",
    "        print(\"Error layer {}\".format(i))\n",
    "        print(\"Error {}\".format(network[3]['e_output']))\n",
    "        print(\"previous output {}\".format(network[2]['output_hl'+str(i-1)]))\n",
    "        #n_W_out = network[0]['W_out'] - alpha * network[3]['e_output'] * network[2]['output_hl'+str(i-1)]\n",
    "        #e_reshape = np.reshape(network[3]['e_output'],(network[3]['e_output'].size,1))\n",
    "        #n_W_out = np.subtract(network[0]['W_out'] , (alpha * np.multiply(e_reshape , network[2]['output_hl'+str(i-1)])))\n",
    "        \"\"\"\n",
    "        n_W_out = np.subtract(network[0]['W_out'] , (alpha * np.multiply(network[3]['e_output'] , network[2]['output_hl'+str(i-1)])))\n",
    "        n_Weights['W_out'] = n_W_out\n",
    "        n_b_out = network[1]['b_out'] - alpha * network[3]['e_output'] #calculates the new bias for the output layer\n",
    "        n_Bias['b_out'] = n_b_out\n",
    "      elif i!=0:\n",
    "        \"\"\"\n",
    "        print(\"Error layer {}\".format(i))\n",
    "        print(\"Error {}\".format(network[3]['e_hl'+str(i)]))\n",
    "        print(\"previous output {}\".format(network[2]['output_hl'+str(i-1)]))\n",
    "        #n_W_hl = network[0]['W_hl'+str(i)] - (alpha * (network[3]['e_hl'+str(i)] * network[2]['output_hl'+str(i-1)])) #Actual weights - alpha *output_error *  activation_input_of_previous_hiddenLayer\n",
    "        \"\"\"\n",
    "        e_reshape = np.reshape(network[3]['e_hl'+str(i)],(network[3]['e_hl'+str(i)].size,1))\n",
    "        n_W_hl = np.subtract(network[0]['W_hl'+str(i)] , (alpha * np.multiply(e_reshape , network[2]['output_hl'+str(i-1)]))) #Actual weights - alpha *output_error *  activation_input_of_previous_hiddenLayer\n",
    "        n_Weights['W_hl'+str(i)] = n_W_hl\n",
    "        n_b_hl = network[1]['b_hl'+str(i)] - (alpha * network[3]['e_hl'+str(i)])\n",
    "        n_Bias['b_hl'+str(i)] = n_b_hl                                     \n",
    "      else:\n",
    "        \"\"\"\n",
    "        print(\"Error layer {}\".format(i))\n",
    "        print(\"Error {}\".format(network[3]['e_hl'+str(i)]))\n",
    "        print(\"previous output {}\".format(x))\n",
    "        #n_W_hl = network[0]['W_hl'+str(i)] - (alpha * (network[3]['e_hl'+str(i)] * x)) #Actual weights - alpha *output_error * actual_input\n",
    "        \"\"\"\n",
    "        e_reshape = np.reshape(network[3]['e_hl'+str(i)],(network[3]['e_hl'+str(i)].size,1))\n",
    "        n_W_hl = np.subtract(network[0]['W_hl'+str(i)] , (alpha * np.multiply(e_reshape , x))) #Actual weights - alpha *output_error * actual_input\n",
    "        n_Weights['W_hl'+str(i)] = n_W_hl   \n",
    "        n_b_hl = network[1]['b_hl'+str(i)] - (alpha * network[3]['e_hl'+str(i)]) #Actual bias - alpha * output_error\n",
    "        n_Bias['b_hl'+str(i)] = n_b_hl\n",
    "    \n",
    "    return(n_Weights,n_Bias)\n",
    "\n",
    "# Testing patterns\n",
    "def testing_patterns(X, network):\n",
    "    \n",
    "    print('       MLP result      ')\n",
    "    print('Pat:          t:      out:')\n",
    "    count = 0\n",
    "    for x in X:\n",
    "        output = feed_forward(x, network)\n",
    "        print('{}. {} ---- {} ----> {:.3f}'.format(count, x, t[count], float(output['output_out'])))\n",
    "        count += 1\n",
    "    \n",
    "# Graph error\n",
    "def graph_error(err_vector):\n",
    "\n",
    "    plt.figure(0)\n",
    "    plt.plot(err_vector)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Error')\n",
    "    plt.title('BP algorithm')\n",
    "    plt.show()\n",
    "\n",
    "# Decision boundaries\n",
    "def dec_boundaries(X, t, network):\n",
    "    \n",
    "    # Creating mesh\n",
    "    h = 0.01\n",
    "    x_min, x_max = -0.2, 1.2\n",
    "    y_min, y_max = -0.2, 1.2\n",
    "\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "\n",
    "    Z = np.c_[xx.ravel(), yy.ravel()]\n",
    "    out = np.zeros(np.shape(Z)[0])\n",
    "    \n",
    "    # Output model\n",
    "    for i in range(len(out)):\n",
    "        outputD =  feed_forward(Z[i], network)\n",
    "        out[i] = outputD['output_out']\n",
    "\n",
    "    # out = (out >= 0.5).astype(int)\n",
    "    out = out.reshape(xx.shape)\n",
    "    levels = np.linspace(0, 1)\n",
    "    plt.figure(1)\n",
    "    plt.contourf(xx, yy, out, levels)\n",
    "    plt.colorbar()\n",
    "\n",
    "    # Plotting data\n",
    "    lis = np.unique(t)\n",
    "    for i in range(len(t)):\n",
    "        if i == 0:\n",
    "            pos = np.where(t == 0)[0]\n",
    "            plt.plot(X[pos][:, 0], X[pos][:, 1], 'o', color = 'white', markersize = 15)\n",
    "\n",
    "        else:\n",
    "            pos = np.where(t == 1)[0]\n",
    "            plt.plot(X[pos][:, 0], X[pos][:, 1], 'x', color = 'red', markersize = 15)\n",
    "\n",
    "    plt.title('Decision boundary')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.show()\n",
    "\n",
    "def def_param(n_layers,X,t):\n",
    "  weights = {}\n",
    "  bias = {}\n",
    "  n_neurons_layer = {}\n",
    "  \"\"\"\n",
    "  initializing weights and bias as follows:\n",
    "  np.random.normal(size=(param1,param2)), size takes two arguments where:\n",
    "  \n",
    "  param1 = no. neurons in the current layer\n",
    "  param2 = no. neurons in the previous layer\n",
    "  \"\"\"\n",
    "  for i in range(n_layers+1):\n",
    "    \n",
    "    if i==0:#if its the first layer\n",
    "      n_neurons = int(input(\"Numero de neuronas en la capa {} \".format(i)))\n",
    "      weights['W_hl'+str(i)] = np.random.normal(size=(n_neurons,X.shape[1]))#the no. of neurons in the previous layers is equal to the input vector length\n",
    "      bias['b_hl'+str(i)] = np.random.normal(size=n_neurons)#the no. of bias is equal to the number of neurons\n",
    "      n_neurons_layer['n_neurons'+str(i)] = n_neurons#stores the number of neurons in the current layer\n",
    "    elif i==n_layers: #if its the output layer\n",
    "      \"\"\"\n",
    "      the number of neurons in the current layer is equal to the target vector length\n",
    "      \"\"\"\n",
    "      #weights['W_out'] = np.random.normal(size=(t.shape[1],n_neurons_layer['n_neurons'+str(i-1)]))\n",
    "      #bias['b_out'] = np.random.normal(size=t.shape[1])\n",
    "      weights['W_out'] = np.random.normal(size=(n_neurons_layer['n_neurons'+str(i-1)]))\n",
    "      bias['b_out'] = np.random.normal(1)\n",
    "      n_neurons_layer['n_neurons'+str(i)] =  1#stores the number of neurons in the current layer\n",
    "    else:#if its any other hidden layer\n",
    "      n_neurons = int(input(\"Numero de neuronas en la capa {} \".format(i)))\n",
    "      weights['W_hl'+str(i)] = np.random.normal(size=(n_neurons,n_neurons_layer['n_neurons'+str(i-1)]))\n",
    "      bias['b_hl'+str(i)] = np.random.normal(size=n_neurons)\n",
    "      n_neurons_layer['n_neurons'+str(i)] =  n_neurons#stores the number of neurons in the current layer\n",
    "  \n",
    "  #print(weights)\n",
    "  #print(bias)\n",
    "  return weights,bias      \n",
    "    \n",
    "# Training patterns and targets\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "\n",
    "t = np.array([0, 0, 0, 1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "colab_type": "code",
    "id": "JtuT0hXviq7e",
    "outputId": "ce6f2bbb-c123-4037-e9b0-8161afdcca28"
   },
   "outputs": [],
   "source": [
    "def_param(2,X,t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9x8gnOdv2VZA"
   },
   "source": [
    "## **Modelo de la red neuronal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dhSR-ozKBH43"
   },
   "outputs": [],
   "source": [
    "\n",
    "def Neural_network_model(X):\n",
    "  \n",
    "  n_hidden_layers = int(input('Número de capas ocultas: '))\n",
    "  #n_nodes_hl1 = int(input('Número de neuronas en capa oculta: '))\n",
    "  # Initial weights\n",
    "  #using a normal(gaussian)distribution\n",
    "  network = []\n",
    "  \n",
    "  layer_output = {}\n",
    "  error_layer = {}\n",
    "  weights,biases = def_param(n_hidden_layers,X,t)\n",
    "  network.append(weights)\n",
    "  network.append(biases)\n",
    "  network.append(layer_output)\n",
    "  network.append(error_layer)\n",
    "  network.append(n_hidden_layers)\n",
    "  \n",
    "  \n",
    "  return network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aV-IBXiyuE45"
   },
   "outputs": [],
   "source": [
    "def Neural_network_model(X):\n",
    "  \n",
    "  n_hidden_layers = 1\n",
    "  n_nodes_hl1 = int(input('Número de neuronas en capa oculta: '))\n",
    "  # Initial weights\n",
    "  #using a normal(gaussian)distribution\n",
    "  network = []\n",
    "  \n",
    "  weights = {\n",
    "      'W_hl0':np.random.normal(size=(n_nodes_hl1,X.shape[1])),\n",
    "      'W_out':np.random.normal(size=(n_nodes_hl1))\n",
    "  }\n",
    "  \n",
    "  \n",
    "  \n",
    "  biases = {\n",
    "      'b_hl0':np.random.normal(size=(n_nodes_hl1)),\n",
    "      'b_out':np.random.normal(size=(1))\n",
    "  }\n",
    "  \n",
    "  \n",
    "  layer_output = {}\n",
    "  error_layer = {}\n",
    "  \n",
    "  network.append(weights)\n",
    "  network.append(biases)\n",
    "  network.append(layer_output)\n",
    "  network.append(error_layer)\n",
    "  network.append(n_hidden_layers)\n",
    "  \n",
    "  \n",
    "  return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "colab_type": "code",
    "id": "vsu2RVlmt_LC",
    "outputId": "bb536ec0-8455-4b97-aa23-1a059a4c91bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de capas ocultas: 4\n",
      "Numero de neuronas en la capa 0 2\n",
      "Numero de neuronas en la capa 1 2\n",
      "Numero de neuronas en la capa 2 2\n",
      "Numero de neuronas en la capa 3 2\n",
      "[{'W_hl0': array([[ 1.22216925,  0.25042195],\n",
      "       [ 0.1492466 , -0.17955758]]), 'W_hl1': array([[ 0.14605094,  0.25456306],\n",
      "       [ 1.4331441 , -0.71575726]]), 'W_hl2': array([[-0.50559693, -1.19035341],\n",
      "       [-0.86414604, -1.10551269]]), 'W_hl3': array([[-0.03868184,  0.87525387],\n",
      "       [ 0.51928448,  0.221482  ]]), 'W_out': array([0.34489185, 1.97550731])}, {'b_hl0': array([-0.86665293, -0.88733729]), 'b_hl1': array([ 0.44768812, -1.12095785]), 'b_hl2': array([-1.30365831, -0.06071498]), 'b_hl3': array([ 0.08172936, -1.69604011]), 'b_out': 2.4710367544229572}, {}, {}, 4]\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.8\n",
    "network = Neural_network_model(X)\n",
    "print(network)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dQYf0XDW2ptR"
   },
   "source": [
    "## **Entrenando la red neuronal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "xZ7jCXgy2xtR",
    "outputId": "5e1ad0db-2b85-485c-d609-6d12482bb3fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 error 0.0015897040139103533\n",
      "Epoch 1 error 0.0015878271433776728\n",
      "Epoch 2 error 0.0015859544092476899\n",
      "Epoch 3 error 0.0015840857981807574\n",
      "Epoch 4 error 0.001582221296893815\n",
      "Epoch 5 error 0.0015803608921601392\n",
      "Epoch 6 error 0.001578504570809032\n",
      "Epoch 7 error 0.0015766523197254943\n",
      "Epoch 8 error 0.0015748041258499988\n",
      "Epoch 9 error 0.001572959976178124\n",
      "Epoch 10 error 0.0015711198577603343\n",
      "Epoch 11 error 0.0015692837577016478\n",
      "Epoch 12 error 0.0015674516631613556\n",
      "Epoch 13 error 0.0015656235613527836\n",
      "Epoch 14 error 0.0015637994395429505\n",
      "Epoch 15 error 0.0015619792850523001\n",
      "Epoch 16 error 0.0015601630852544774\n",
      "Epoch 17 error 0.0015583508275759802\n",
      "Epoch 18 error 0.0015565424994959279\n",
      "Epoch 19 error 0.001554738088545796\n",
      "Epoch 20 error 0.0015529375823090871\n",
      "Epoch 21 error 0.0015511409684211257\n",
      "Epoch 22 error 0.0015493482345687781\n",
      "Epoch 23 error 0.001547559368490136\n",
      "Epoch 24 error 0.0015457743579743305\n",
      "Epoch 25 error 0.0015439931908611997\n",
      "Epoch 26 error 0.0015422158550410724\n",
      "Epoch 27 error 0.0015404423384544775\n",
      "Epoch 28 error 0.0015386726290919236\n",
      "Epoch 29 error 0.00153690671499359\n",
      "Epoch 30 error 0.0015351445842491226\n",
      "Epoch 31 error 0.0015333862249973693\n",
      "Epoch 32 error 0.0015316316254260793\n",
      "Epoch 33 error 0.0015298807737717298\n",
      "Epoch 34 error 0.0015281336583192165\n",
      "Epoch 35 error 0.0015263902674016497\n",
      "Epoch 36 error 0.0015246505894000728\n",
      "Epoch 37 error 0.0015229146127432275\n",
      "Epoch 38 error 0.0015211823259073344\n",
      "Epoch 39 error 0.0015194537174158195\n",
      "Epoch 40 error 0.0015177287758390964\n",
      "Epoch 41 error 0.001516007489794322\n",
      "Epoch 42 error 0.0015142898479451616\n",
      "Epoch 43 error 0.001512575839001535\n",
      "Epoch 44 error 0.0015108654517194027\n",
      "Epoch 45 error 0.0015091586749005396\n",
      "Epoch 46 error 0.0015074554973922819\n",
      "Epoch 47 error 0.001505755908087313\n",
      "Epoch 48 error 0.0015040598959234193\n",
      "Epoch 49 error 0.0015023674498832892\n",
      "Epoch 50 error 0.0015006785589942529\n",
      "Epoch 51 error 0.0014989932123280884\n",
      "Epoch 52 error 0.0014973113990007926\n",
      "Epoch 53 error 0.001495633108172329\n",
      "Epoch 54 error 0.0014939583290464725\n",
      "Epoch 55 error 0.0014922870508705065\n",
      "Epoch 56 error 0.0014906192629350725\n",
      "Epoch 57 error 0.0014889549545739195\n",
      "Epoch 58 error 0.001487294115163725\n",
      "Epoch 59 error 0.001485636734123799\n",
      "Epoch 60 error 0.0014839828009159959\n",
      "Epoch 61 error 0.0014823323050443824\n",
      "Epoch 62 error 0.001480685236055102\n",
      "Epoch 63 error 0.0014790415835361451\n",
      "Epoch 64 error 0.0014774013371171328\n",
      "Epoch 65 error 0.0014757644864691125\n",
      "Epoch 66 error 0.0014741310213043754\n",
      "Epoch 67 error 0.001472500931376222\n",
      "Epoch 68 error 0.0014708742064787716\n",
      "Epoch 69 error 0.0014692508364467713\n",
      "Epoch 70 error 0.0014676308111553787\n",
      "Epoch 71 error 0.0014660141205199732\n",
      "Epoch 72 error 0.0014644007544959555\n",
      "Epoch 73 error 0.0014627907030785332\n",
      "Epoch 74 error 0.0014611839563025814\n",
      "Epoch 75 error 0.0014595805042423508\n",
      "Epoch 76 error 0.0014579803370113973\n",
      "Epoch 77 error 0.0014563834447622707\n",
      "Epoch 78 error 0.0014547898176864144\n",
      "Epoch 79 error 0.001453199446013912\n",
      "Epoch 80 error 0.0014516123200133356\n",
      "Epoch 81 error 0.0014500284299915466\n",
      "Epoch 82 error 0.0014484477662935198\n",
      "Epoch 83 error 0.0014468703193021245\n",
      "Epoch 84 error 0.001445296079437975\n",
      "Epoch 85 error 0.0014437250371592443\n",
      "Epoch 86 error 0.0014421571829614601\n",
      "Epoch 87 error 0.001440592507377332\n",
      "Epoch 88 error 0.0014390310009765833\n",
      "Epoch 89 error 0.001437472654365766\n",
      "Epoch 90 error 0.0014359174581880633\n",
      "Epoch 91 error 0.0014343654031231598\n",
      "Epoch 92 error 0.0014328164798869864\n",
      "Epoch 93 error 0.0014312706792316467\n",
      "Epoch 94 error 0.0014297279919451417\n",
      "Epoch 95 error 0.001428188408851276\n",
      "Epoch 96 error 0.0014266519208094388\n",
      "Epoch 97 error 0.0014251185187144555\n",
      "Epoch 98 error 0.001423588193496398\n",
      "Epoch 99 error 0.001422060936120436\n",
      "Epoch 100 error 0.001420536737586655\n",
      "Epoch 101 error 0.0014190155889299005\n",
      "Epoch 102 error 0.0014174974812196013\n",
      "Epoch 103 error 0.0014159824055596049\n",
      "Epoch 104 error 0.0014144703530880143\n",
      "Epoch 105 error 0.0014129613149770196\n",
      "Epoch 106 error 0.0014114552824327654\n",
      "Epoch 107 error 0.001409952246695143\n",
      "Epoch 108 error 0.0014084521990376637\n",
      "Epoch 109 error 0.001406955130767282\n",
      "Epoch 110 error 0.0014054610332242378\n",
      "Epoch 111 error 0.0014039698977819145\n",
      "Epoch 112 error 0.001402481715846655\n",
      "Epoch 113 error 0.001400996478857633\n",
      "Epoch 114 error 0.0013995141782866824\n",
      "Epoch 115 error 0.0013980348056381368\n",
      "Epoch 116 error 0.0013965583524486998\n",
      "Epoch 117 error 0.0013950848102872605\n",
      "Epoch 118 error 0.0013936141707547724\n",
      "Epoch 119 error 0.0013921464254840771\n",
      "Epoch 120 error 0.001390681566139764\n",
      "Epoch 121 error 0.0013892195844180377\n",
      "Epoch 122 error 0.00138776047204653\n",
      "Epoch 123 error 0.0013863042207842026\n",
      "Epoch 124 error 0.0013848508224211507\n",
      "Epoch 125 error 0.0013834002687784991\n",
      "Epoch 126 error 0.0013819525517082115\n",
      "Epoch 127 error 0.0013805076630930067\n",
      "Epoch 128 error 0.001379065594846152\n",
      "Epoch 129 error 0.0013776263389113563\n",
      "Epoch 130 error 0.0013761898872626393\n",
      "Epoch 131 error 0.0013747562319041504\n",
      "Epoch 132 error 0.0013733253648700549\n",
      "Epoch 133 error 0.0013718972782243866\n",
      "Epoch 134 error 0.0013704719640609282\n",
      "Epoch 135 error 0.0013690494145030406\n",
      "Epoch 136 error 0.0013676296217035326\n",
      "Epoch 137 error 0.0013662125778445614\n",
      "Epoch 138 error 0.0013647982751374532\n",
      "Epoch 139 error 0.0013633867058225734\n",
      "Epoch 140 error 0.0013619778621692174\n",
      "Epoch 141 error 0.0013605717364754677\n",
      "Epoch 142 error 0.0013591683210680341\n",
      "Epoch 143 error 0.0013577676083021554\n",
      "Epoch 144 error 0.0013563695905614613\n",
      "Epoch 145 error 0.0013549742602578206\n",
      "Epoch 146 error 0.0013535816098312445\n",
      "Epoch 147 error 0.0013521916317497237\n",
      "Epoch 148 error 0.001350804318509127\n",
      "Epoch 149 error 0.0013494196626330597\n",
      "Epoch 150 error 0.0013480376566727282\n",
      "Epoch 151 error 0.0013466582932068398\n",
      "Epoch 152 error 0.0013452815648414516\n",
      "Epoch 153 error 0.0013439074642098625\n",
      "Epoch 154 error 0.001342535983972481\n",
      "Epoch 155 error 0.0013411671168166953\n",
      "Epoch 156 error 0.0013398008554567561\n",
      "Epoch 157 error 0.001338437192633672\n",
      "Epoch 158 error 0.0013370761211150492\n",
      "Epoch 159 error 0.0013357176336950096\n",
      "Epoch 160 error 0.0013343617231940377\n",
      "Epoch 161 error 0.0013330083824588995\n",
      "Epoch 162 error 0.001331657604362464\n",
      "Epoch 163 error 0.0013303093818036705\n",
      "Epoch 164 error 0.0013289637077073188\n",
      "Epoch 165 error 0.001327620575024014\n",
      "Epoch 166 error 0.0013262799767300231\n",
      "Epoch 167 error 0.0013249419058271772\n",
      "Epoch 168 error 0.0013236063553427337\n",
      "Epoch 169 error 0.0013222733183292875\n",
      "Epoch 170 error 0.0013209427878646332\n",
      "Epoch 171 error 0.001319614757051653\n",
      "Epoch 172 error 0.0013182892190182365\n",
      "Epoch 173 error 0.0013169661669171142\n",
      "Epoch 174 error 0.0013156455939258198\n",
      "Epoch 175 error 0.0013143274932464824\n",
      "Epoch 176 error 0.001313011858105818\n",
      "Epoch 177 error 0.001311698681754933\n",
      "Epoch 178 error 0.0013103879574692813\n",
      "Epoch 179 error 0.001309079678548515\n",
      "Epoch 180 error 0.0013077738383163835\n",
      "Epoch 181 error 0.0013064704301206328\n",
      "Epoch 182 error 0.0013051694473329152\n",
      "Epoch 183 error 0.0013038708833486405\n",
      "Epoch 184 error 0.001302574731586911\n",
      "Epoch 185 error 0.0013012809854903865\n",
      "Epoch 186 error 0.0012999896385252016\n",
      "Epoch 187 error 0.001298700684180859\n",
      "Epoch 188 error 0.0012974141159701094\n",
      "Epoch 189 error 0.00129612992742885\n",
      "Epoch 190 error 0.0012948481121160516\n",
      "Epoch 191 error 0.0012935686636136262\n",
      "Epoch 192 error 0.0012922915755263298\n",
      "Epoch 193 error 0.0012910168414816863\n",
      "Epoch 194 error 0.0012897444551298442\n",
      "Epoch 195 error 0.0012884744101435118\n",
      "Epoch 196 error 0.0012872067002178476\n",
      "Epoch 197 error 0.0012859413190703655\n",
      "Epoch 198 error 0.0012846782604408148\n",
      "Epoch 199 error 0.0012834175180911089\n",
      "Epoch 200 error 0.0012821590858052316\n",
      "Epoch 201 error 0.0012809029573891038\n",
      "Epoch 202 error 0.001279649126670526\n",
      "Epoch 203 error 0.0012783975874990645\n",
      "Epoch 204 error 0.0012771483337459565\n",
      "Epoch 205 error 0.0012759013593040183\n",
      "Epoch 206 error 0.0012746566580875587\n",
      "Epoch 207 error 0.001273414224032272\n",
      "Epoch 208 error 0.001272174051095149\n",
      "Epoch 209 error 0.001270936133254371\n",
      "Epoch 210 error 0.0012697004645092673\n",
      "Epoch 211 error 0.0012684670388801616\n",
      "Epoch 212 error 0.0012672358504083\n",
      "Epoch 213 error 0.0012660068931558076\n",
      "Epoch 214 error 0.001264780161205504\n",
      "Epoch 215 error 0.0012635556486609112\n",
      "Epoch 216 error 0.0012623333496461016\n",
      "Epoch 217 error 0.001261113258305626\n",
      "Epoch 218 error 0.0012598953688044293\n",
      "Epoch 219 error 0.0012586796753277715\n",
      "Epoch 220 error 0.0012574661720811129\n",
      "Epoch 221 error 0.001256254853290045\n",
      "Epoch 222 error 0.0012550457132002018\n",
      "Epoch 223 error 0.0012538387460771972\n",
      "Epoch 224 error 0.0012526339462064695\n",
      "Epoch 225 error 0.0012514313078932772\n",
      "Epoch 226 error 0.0012502308254625704\n",
      "Epoch 227 error 0.001249032493258915\n",
      "Epoch 228 error 0.0012478363056463884\n",
      "Epoch 229 error 0.0012466422570085438\n",
      "Epoch 230 error 0.0012454503417482954\n",
      "Epoch 231 error 0.001244260554287821\n",
      "Epoch 232 error 0.00124307288906851\n",
      "Epoch 233 error 0.0012418873405508572\n",
      "Epoch 234 error 0.0012407039032144187\n",
      "Epoch 235 error 0.0012395225715576867\n",
      "Epoch 236 error 0.0012383433400980127\n",
      "Epoch 237 error 0.0012371662033715826\n",
      "Epoch 238 error 0.0012359911559332584\n",
      "Epoch 239 error 0.001234818192356553\n",
      "Epoch 240 error 0.0012336473072335403\n",
      "Epoch 241 error 0.001232478495174748\n",
      "Epoch 242 error 0.001231311750809126\n",
      "Epoch 243 error 0.0012301470687839334\n",
      "Epoch 244 error 0.00122898444376468\n",
      "Epoch 245 error 0.0012278238704350232\n",
      "Epoch 246 error 0.0012266653434967333\n",
      "Epoch 247 error 0.001225508857669584\n",
      "Epoch 248 error 0.0012243544076912683\n",
      "Epoch 249 error 0.0012232019883173617\n",
      "Epoch 250 error 0.0012220515943212357\n",
      "Epoch 251 error 0.0012209032204939464\n",
      "Epoch 252 error 0.0012197568616441937\n",
      "Epoch 253 error 0.0012186125125982525\n",
      "Epoch 254 error 0.0012174701681998774\n",
      "Epoch 255 error 0.001216329823310235\n",
      "Epoch 256 error 0.0012151914728078454\n",
      "Epoch 257 error 0.0012140551115885022\n",
      "Epoch 258 error 0.001212920734565178\n",
      "Epoch 259 error 0.0012117883366679905\n",
      "Epoch 260 error 0.0012106579128440974\n",
      "Epoch 261 error 0.0012095294580576534\n",
      "Epoch 262 error 0.0012084029672897257\n",
      "Epoch 263 error 0.0012072784355381967\n",
      "Epoch 264 error 0.0012061558578177621\n",
      "Epoch 265 error 0.001205035229159805\n",
      "Epoch 266 error 0.0012039165446123192\n",
      "Epoch 267 error 0.0012027997992398944\n",
      "Epoch 268 error 0.0012016849881236026\n",
      "Epoch 269 error 0.001200572106360936\n",
      "Epoch 270 error 0.001199461149065749\n",
      "Epoch 271 error 0.0011983521113682035\n",
      "Epoch 272 error 0.0011972449884146772\n",
      "Epoch 273 error 0.001196139775367678\n",
      "Epoch 274 error 0.00119503646740585\n",
      "Epoch 275 error 0.0011939350597238252\n",
      "Epoch 276 error 0.0011928355475322033\n",
      "Epoch 277 error 0.0011917379260574946\n",
      "Epoch 278 error 0.0011906421905420114\n",
      "Epoch 279 error 0.0011895483362438417\n",
      "Epoch 280 error 0.0011884563584367638\n",
      "Epoch 281 error 0.0011873662524101841\n",
      "Epoch 282 error 0.0011862780134690978\n",
      "Epoch 283 error 0.0011851916369339786\n",
      "Epoch 284 error 0.0011841071181407591\n",
      "Epoch 285 error 0.001183024452440745\n",
      "Epoch 286 error 0.001181943635200563\n",
      "Epoch 287 error 0.0011808646618020723\n",
      "Epoch 288 error 0.0011797875276423492\n",
      "Epoch 289 error 0.001178712228133572\n",
      "Epoch 290 error 0.0011776387587030075\n",
      "Epoch 291 error 0.0011765671147929298\n",
      "Epoch 292 error 0.001175497291860529\n",
      "Epoch 293 error 0.0011744292853779026\n",
      "Epoch 294 error 0.0011733630908319576\n",
      "Epoch 295 error 0.0011722987037243856\n",
      "Epoch 296 error 0.0011712361195715649\n",
      "Epoch 297 error 0.001170175333904502\n",
      "Epoch 298 error 0.0011691163422688266\n",
      "Epoch 299 error 0.0011680591402246478\n",
      "Epoch 300 error 0.0011670037233465847\n",
      "Epoch 301 error 0.001165950087223633\n",
      "Epoch 302 error 0.001164898227459155\n",
      "Epoch 303 error 0.0011638481396707876\n",
      "Epoch 304 error 0.0011627998194904277\n",
      "Epoch 305 error 0.001161753262564117\n",
      "Epoch 306 error 0.0011607084645520484\n",
      "Epoch 307 error 0.00115966542112846\n",
      "Epoch 308 error 0.0011586241279816028\n",
      "Epoch 309 error 0.0011575845808136662\n",
      "Epoch 310 error 0.0011565467753407428\n",
      "Epoch 311 error 0.00115551070729277\n",
      "Epoch 312 error 0.0011544763724134635\n",
      "Epoch 313 error 0.001153443766460262\n",
      "Epoch 314 error 0.0011524128852042808\n",
      "Epoch 315 error 0.0011513837244302586\n",
      "Epoch 316 error 0.0011503562799364824\n",
      "Epoch 317 error 0.0011493305475347663\n",
      "Epoch 318 error 0.0011483065230503747\n",
      "Epoch 319 error 0.0011472842023219736\n",
      "Epoch 320 error 0.0011462635812015689\n",
      "Epoch 321 error 0.0011452446555544923\n",
      "Epoch 322 error 0.001144227421259273\n",
      "Epoch 323 error 0.001143211874207678\n",
      "Epoch 324 error 0.0011421980103045698\n",
      "Epoch 325 error 0.0011411858254679321\n",
      "Epoch 326 error 0.001140175315628759\n",
      "Epoch 327 error 0.00113916647673105\n",
      "Epoch 328 error 0.0011381593047316975\n",
      "Epoch 329 error 0.001137153795600518\n",
      "Epoch 330 error 0.0011361499453201333\n",
      "Epoch 331 error 0.0011351477498859415\n",
      "Epoch 332 error 0.0011341472053060797\n",
      "Epoch 333 error 0.0011331483076013585\n",
      "Epoch 334 error 0.0011321510528052156\n",
      "Epoch 335 error 0.0011311554369636719\n",
      "Epoch 336 error 0.0011301614561352643\n",
      "Epoch 337 error 0.0011291691063910277\n",
      "Epoch 338 error 0.0011281783838144126\n",
      "Epoch 339 error 0.001127189284501264\n",
      "Epoch 340 error 0.0011262018045597394\n",
      "Epoch 341 error 0.0011252159401103088\n",
      "Epoch 342 error 0.001124231687285649\n",
      "Epoch 343 error 0.0011232490422306571\n",
      "Epoch 344 error 0.0011222680011023559\n",
      "Epoch 345 error 0.0011212885600698553\n",
      "Epoch 346 error 0.001120310715314325\n",
      "Epoch 347 error 0.0011193344630289234\n",
      "Epoch 348 error 0.0011183597994187835\n",
      "Epoch 349 error 0.0011173867207009047\n",
      "Epoch 350 error 0.0011164152231041805\n",
      "Epoch 351 error 0.0011154453028693213\n",
      "Epoch 352 error 0.0011144769562487784\n",
      "Epoch 353 error 0.0011135101795067422\n",
      "Epoch 354 error 0.0011125449689190817\n",
      "Epoch 355 error 0.001111581320773291\n",
      "Epoch 356 error 0.0011106192313684623\n",
      "Epoch 357 error 0.0011096586970152102\n",
      "Epoch 358 error 0.001108699714035661\n",
      "Epoch 359 error 0.001107742278763393\n",
      "Epoch 360 error 0.0011067863875433817\n",
      "Epoch 361 error 0.0011058320367319874\n",
      "Epoch 362 error 0.00110487922269687\n",
      "Epoch 363 error 0.0011039279418169885\n",
      "Epoch 364 error 0.0011029781904825032\n",
      "Epoch 365 error 0.0011020299650948027\n",
      "Epoch 366 error 0.0011010832620663947\n",
      "Epoch 367 error 0.001100138077820903\n",
      "Epoch 368 error 0.001099194408793012\n",
      "Epoch 369 error 0.001098252251428429\n",
      "Epoch 370 error 0.001097311602183819\n",
      "Epoch 371 error 0.0010963724575268246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 372 error 0.00109543481393594\n",
      "Epoch 373 error 0.001094498667900525\n",
      "Epoch 374 error 0.0010935640159207513\n",
      "Epoch 375 error 0.0010926308545075704\n",
      "Epoch 376 error 0.0010916991801826347\n",
      "Epoch 377 error 0.001090768989478309\n",
      "Epoch 378 error 0.0010898402789375936\n",
      "Epoch 379 error 0.0010889130451140925\n",
      "Epoch 380 error 0.0010879872845719848\n",
      "Epoch 381 error 0.0010870629938859618\n",
      "Epoch 382 error 0.0010861401696412067\n",
      "Epoch 383 error 0.0010852188084333509\n",
      "Epoch 384 error 0.0010842989068684241\n",
      "Epoch 385 error 0.001083380461562829\n",
      "Epoch 386 error 0.0010824634691432868\n",
      "Epoch 387 error 0.0010815479262468262\n",
      "Epoch 388 error 0.0010806338295207031\n",
      "Epoch 389 error 0.0010797211756223921\n",
      "Epoch 390 error 0.0010788099612195367\n",
      "Epoch 391 error 0.0010779001829899254\n",
      "Epoch 392 error 0.0010769918376214238\n",
      "Epoch 393 error 0.001076084921811969\n",
      "Epoch 394 error 0.0010751794322695091\n",
      "Epoch 395 error 0.0010742753657119782\n",
      "Epoch 396 error 0.0010733727188672493\n",
      "Epoch 397 error 0.001072471488473111\n",
      "Epoch 398 error 0.0010715716712772173\n",
      "Epoch 399 error 0.0010706732640370458\n",
      "Epoch 400 error 0.0010697762635198758\n",
      "Epoch 401 error 0.001068880666502753\n",
      "Epoch 402 error 0.0010679864697724414\n",
      "Epoch 403 error 0.0010670936701253782\n",
      "Epoch 404 error 0.0010662022643676697\n",
      "Epoch 405 error 0.0010653122493150184\n",
      "Epoch 406 error 0.0010644236217927216\n",
      "Epoch 407 error 0.0010635363786355985\n",
      "Epoch 408 error 0.0010626505166879984\n",
      "Epoch 409 error 0.0010617660328037203\n",
      "Epoch 410 error 0.001060882923846011\n",
      "Epoch 411 error 0.0010600011866875158\n",
      "Epoch 412 error 0.0010591208182102398\n",
      "Epoch 413 error 0.0010582418153055372\n",
      "Epoch 414 error 0.0010573641748740292\n",
      "Epoch 415 error 0.0010564878938256262\n",
      "Epoch 416 error 0.001055612969079446\n",
      "Epoch 417 error 0.0010547393975638255\n",
      "Epoch 418 error 0.0010538671762162209\n",
      "Epoch 419 error 0.001052996301983257\n",
      "Epoch 420 error 0.0010521267718206183\n",
      "Epoch 421 error 0.0010512585826930633\n",
      "Epoch 422 error 0.0010503917315743748\n",
      "Epoch 423 error 0.00104952621544732\n",
      "Epoch 424 error 0.0010486620313036284\n",
      "Epoch 425 error 0.0010477991761439584\n",
      "Epoch 426 error 0.0010469376469778567\n",
      "Epoch 427 error 0.001046077440823724\n",
      "Epoch 428 error 0.0010452185547087955\n",
      "Epoch 429 error 0.0010443609856691104\n",
      "Epoch 430 error 0.0010435047307494462\n",
      "Epoch 431 error 0.001042649787003336\n",
      "Epoch 432 error 0.0010417961514929972\n",
      "Epoch 433 error 0.0010409438212893119\n",
      "Epoch 434 error 0.0010400927934717998\n",
      "Epoch 435 error 0.001039243065128602\n",
      "Epoch 436 error 0.0010383946333563966\n",
      "Epoch 437 error 0.001037547495260433\n",
      "Epoch 438 error 0.0010367016479544524\n",
      "Epoch 439 error 0.0010358570885606916\n",
      "Epoch 440 error 0.0010350138142098046\n",
      "Epoch 441 error 0.0010341718220408937\n",
      "Epoch 442 error 0.0010333311092014328\n",
      "Epoch 443 error 0.0010324916728472488\n",
      "Epoch 444 error 0.0010316535101425007\n",
      "Epoch 445 error 0.0010308166182596448\n",
      "Epoch 446 error 0.001029980994379392\n",
      "Epoch 447 error 0.0010291466356906935\n",
      "Epoch 448 error 0.001028313539390703\n",
      "Epoch 449 error 0.0010274817026847682\n",
      "Epoch 450 error 0.0010266511227863563\n",
      "Epoch 451 error 0.0010258217969170546\n",
      "Epoch 452 error 0.001024993722306562\n",
      "Epoch 453 error 0.001024166896192603\n",
      "Epoch 454 error 0.0010233413158209504\n",
      "Epoch 455 error 0.0010225169784453788\n",
      "Epoch 456 error 0.0010216938813276217\n",
      "Epoch 457 error 0.00102087202173736\n",
      "Epoch 458 error 0.0010200513969521848\n",
      "Epoch 459 error 0.0010192320042575896\n",
      "Epoch 460 error 0.0010184138409469082\n",
      "Epoch 461 error 0.0010175969043212984\n",
      "Epoch 462 error 0.0010167811916897368\n",
      "Epoch 463 error 0.00101596670036896\n",
      "Epoch 464 error 0.0010151534276834568\n",
      "Epoch 465 error 0.0010143413709654341\n",
      "Epoch 466 error 0.0010135305275547654\n",
      "Epoch 467 error 0.0010127208947990258\n",
      "Epoch 468 error 0.0010119124700533877\n",
      "Epoch 469 error 0.0010111052506806576\n",
      "Epoch 470 error 0.0010102992340512086\n",
      "Epoch 471 error 0.0010094944175429738\n",
      "Epoch 472 error 0.0010086907985414077\n",
      "Epoch 473 error 0.00100788837443947\n",
      "Epoch 474 error 0.001007087142637577\n",
      "Epoch 475 error 0.0010062871005436153\n",
      "Epoch 476 error 0.001005488245572882\n",
      "Epoch 477 error 0.0010046905751480589\n",
      "Epoch 478 error 0.0010038940866991994\n",
      "Epoch 479 error 0.0010030987776637125\n",
      "Epoch 480 error 0.0010023046454862954\n",
      "Epoch 481 error 0.0010015116876189696\n",
      "Epoch 482 error 0.0010007199015209807\n",
      "Epoch 483 error 0.0009999292846588495\n",
      "Epoch 484 error 0.0009991398345062755\n",
      "Epoch 485 error 0.000998351548544166\n",
      "Epoch 486 error 0.0009975644242605915\n",
      "Epoch 487 error 0.0009967784591507413\n",
      "Epoch 488 error 0.0009959936507169436\n",
      "Epoch 489 error 0.000995209996468572\n",
      "Epoch 490 error 0.0009944274939221007\n",
      "Epoch 491 error 0.000993646140601017\n",
      "Epoch 492 error 0.000992865934035826\n",
      "Epoch 493 error 0.0009920868717640252\n",
      "Epoch 494 error 0.0009913089513300683\n",
      "Epoch 495 error 0.000990532170285338\n",
      "Epoch 496 error 0.0009897565261881595\n",
      "Epoch 497 error 0.0009889820166037102\n",
      "Epoch 498 error 0.0009882086391040624\n",
      "Epoch 499 error 0.0009874363912681181\n",
      "Epoch 500 error 0.0009866652706815872\n",
      "Epoch 501 error 0.0009858952749369964\n",
      "Epoch 502 error 0.0009851264016336203\n",
      "Epoch 503 error 0.0009843586483774865\n",
      "Epoch 504 error 0.0009835920127813618\n",
      "Epoch 505 error 0.0009828264924646737\n",
      "Epoch 506 error 0.0009820620850535772\n",
      "Epoch 507 error 0.0009812987881808307\n",
      "Epoch 508 error 0.0009805365994858583\n",
      "Epoch 509 error 0.000979775516614673\n",
      "Epoch 510 error 0.0009790155372198712\n",
      "Epoch 511 error 0.0009782566589606153\n",
      "Epoch 512 error 0.0009774988795026064\n",
      "Epoch 513 error 0.0009767421965180588\n",
      "Epoch 514 error 0.000975986607685679\n",
      "Epoch 515 error 0.0009752321106906436\n",
      "Epoch 516 error 0.0009744787032245866\n",
      "Epoch 517 error 0.0009737263829855567\n",
      "Epoch 518 error 0.0009729751476780062\n",
      "Epoch 519 error 0.0009722249950127746\n",
      "Epoch 520 error 0.0009714759227070653\n",
      "Epoch 521 error 0.0009707279284843925\n",
      "Epoch 522 error 0.0009699810100746262\n",
      "Epoch 523 error 0.0009692351652139043\n",
      "Epoch 524 error 0.0009684903916446377\n",
      "Epoch 525 error 0.0009677466871155034\n",
      "Epoch 526 error 0.0009670040493813961\n",
      "Epoch 527 error 0.000966262476203412\n",
      "Epoch 528 error 0.0009655219653488522\n",
      "Epoch 529 error 0.0009647825145911686\n",
      "Epoch 530 error 0.0009640441217099617\n",
      "Epoch 531 error 0.0009633067844909594\n",
      "Epoch 532 error 0.0009625705007259835\n",
      "Epoch 533 error 0.0009618352682129571\n",
      "Epoch 534 error 0.0009611010847558277\n",
      "Epoch 535 error 0.0009603679481646251\n",
      "Epoch 536 error 0.0009596358562553637\n",
      "Epoch 537 error 0.000958904806850074\n",
      "Epoch 538 error 0.000958174797776771\n",
      "Epoch 539 error 0.0009574458268694125\n",
      "Epoch 540 error 0.0009567178919679074\n",
      "Epoch 541 error 0.0009559909909180634\n",
      "Epoch 542 error 0.0009552651215716042\n",
      "Epoch 543 error 0.0009545402817861271\n",
      "Epoch 544 error 0.0009538164694250893\n",
      "Epoch 545 error 0.0009530936823577656\n",
      "Epoch 546 error 0.0009523719184592851\n",
      "Epoch 547 error 0.0009516511756105349\n",
      "Epoch 548 error 0.0009509314516982213\n",
      "Epoch 549 error 0.0009502127446147674\n",
      "Epoch 550 error 0.0009494950522583722\n",
      "Epoch 551 error 0.000948778372532935\n",
      "Epoch 552 error 0.0009480627033480573\n",
      "Epoch 553 error 0.0009473480426190366\n",
      "Epoch 554 error 0.0009466343882668069\n",
      "Epoch 555 error 0.0009459217382179799\n",
      "Epoch 556 error 0.000945210090404757\n",
      "Epoch 557 error 0.0009444994427649693\n",
      "Epoch 558 error 0.000943789793242034\n",
      "Epoch 559 error 0.0009430811397849112\n",
      "Epoch 560 error 0.000942373480348132\n",
      "Epoch 561 error 0.0009416668128917625\n",
      "Epoch 562 error 0.0009409611353813644\n",
      "Epoch 563 error 0.0009402564457880059\n",
      "Epoch 564 error 0.000939552742088226\n",
      "Epoch 565 error 0.0009388500222640096\n",
      "Epoch 566 error 0.000938148284302802\n",
      "Epoch 567 error 0.0009374475261974482\n",
      "Epoch 568 error 0.0009367477459462112\n",
      "Epoch 569 error 0.0009360489415527269\n",
      "Epoch 570 error 0.0009353511110260057\n",
      "Epoch 571 error 0.0009346542523804046\n",
      "Epoch 572 error 0.000933958363635609\n",
      "Epoch 573 error 0.0009332634428166007\n",
      "Epoch 574 error 0.0009325694879537003\n",
      "Epoch 575 error 0.0009318764970824621\n",
      "Epoch 576 error 0.0009311844682437211\n",
      "Epoch 577 error 0.0009304933994835435\n",
      "Epoch 578 error 0.00092980328885325\n",
      "Epoch 579 error 0.0009291141344093298\n",
      "Epoch 580 error 0.000928425934213481\n",
      "Epoch 581 error 0.0009277386863325806\n",
      "Epoch 582 error 0.0009270523888386498\n",
      "Epoch 583 error 0.0009263670398088645\n",
      "Epoch 584 error 0.0009256826373255051\n",
      "Epoch 585 error 0.0009249991794759618\n",
      "Epoch 586 error 0.0009243166643527207\n",
      "Epoch 587 error 0.0009236350900533351\n",
      "Epoch 588 error 0.0009229544546804219\n",
      "Epoch 589 error 0.0009222747563416132\n",
      "Epoch 590 error 0.0009215959931495826\n",
      "Epoch 591 error 0.0009209181632220027\n",
      "Epoch 592 error 0.0009202412646815478\n",
      "Epoch 593 error 0.0009195652956558312\n",
      "Epoch 594 error 0.0009188902542774532\n",
      "Epoch 595 error 0.0009182161386839431\n",
      "Epoch 596 error 0.0009175429470177578\n",
      "Epoch 597 error 0.0009168706774262521\n",
      "Epoch 598 error 0.0009161993280616804\n",
      "Epoch 599 error 0.0009155288970811666\n",
      "Epoch 600 error 0.000914859382646702\n",
      "Epoch 601 error 0.0009141907829251093\n",
      "Epoch 602 error 0.0009135230960880457\n",
      "Epoch 603 error 0.0009128563203119804\n",
      "Epoch 604 error 0.000912190453778182\n",
      "Epoch 605 error 0.0009115254946726925\n",
      "Epoch 606 error 0.0009108614411863161\n",
      "Epoch 607 error 0.0009101982915146244\n",
      "Epoch 608 error 0.0009095360438578995\n",
      "Epoch 609 error 0.0009088746964211478\n",
      "Epoch 610 error 0.000908214247414102\n",
      "Epoch 611 error 0.0009075546950511516\n",
      "Epoch 612 error 0.0009068960375513632\n",
      "Epoch 613 error 0.0009062382731384847\n",
      "Epoch 614 error 0.0009055814000408801\n",
      "Epoch 615 error 0.0009049254164915483\n",
      "Epoch 616 error 0.0009042703207281133\n",
      "Epoch 617 error 0.0009036161109927758\n",
      "Epoch 618 error 0.0009029627855323378\n",
      "Epoch 619 error 0.0009023103425981579\n",
      "Epoch 620 error 0.0009016587804461363\n",
      "Epoch 621 error 0.0009010080973367405\n",
      "Epoch 622 error 0.0009003582915349428\n",
      "Epoch 623 error 0.0008997093613102231\n",
      "Epoch 624 error 0.0008990613049365563\n",
      "Epoch 625 error 0.000898414120692413\n",
      "Epoch 626 error 0.0008977678068607018\n",
      "Epoch 627 error 0.0008971223617288051\n",
      "Epoch 628 error 0.0008964777835885423\n",
      "Epoch 629 error 0.0008958340707361369\n",
      "Epoch 630 error 0.0008951912214722309\n",
      "Epoch 631 error 0.0008945492341018654\n",
      "Epoch 632 error 0.0008939081069344521\n",
      "Epoch 633 error 0.0008932678382837785\n",
      "Epoch 634 error 0.0008926284264679827\n",
      "Epoch 635 error 0.0008919898698095265\n",
      "Epoch 636 error 0.0008913521666352173\n",
      "Epoch 637 error 0.0008907153152761535\n",
      "Epoch 638 error 0.000890079314067747\n",
      "Epoch 639 error 0.0008894441613496823\n",
      "Epoch 640 error 0.0008888098554659107\n",
      "Epoch 641 error 0.0008881763947646551\n",
      "Epoch 642 error 0.0008875437775983559\n",
      "Epoch 643 error 0.0008869120023237104\n",
      "Epoch 644 error 0.0008862810673016055\n",
      "Epoch 645 error 0.0008856509708971338\n",
      "Epoch 646 error 0.0008850217114796036\n",
      "Epoch 647 error 0.0008843932874224567\n",
      "Epoch 648 error 0.0008837656971033342\n",
      "Epoch 649 error 0.0008831389389039952\n",
      "Epoch 650 error 0.0008825130112103553\n",
      "Epoch 651 error 0.0008818879124124486\n",
      "Epoch 652 error 0.0008812636409044062\n",
      "Epoch 653 error 0.0008806401950844644\n",
      "Epoch 654 error 0.0008800175733549508\n",
      "Epoch 655 error 0.0008793957741222388\n",
      "Epoch 656 error 0.0008787747957967964\n",
      "Epoch 657 error 0.000878154636793098\n",
      "Epoch 658 error 0.0008775352955296817\n",
      "Epoch 659 error 0.0008769167704290807\n",
      "Epoch 660 error 0.0008762990599178396\n",
      "Epoch 661 error 0.000875682162426506\n",
      "Epoch 662 error 0.000875066076389615\n",
      "Epoch 663 error 0.0008744508002456391\n",
      "Epoch 664 error 0.0008738363324370481\n",
      "Epoch 665 error 0.0008732226714102183\n",
      "Epoch 666 error 0.0008726098156154873\n",
      "Epoch 667 error 0.0008719977635070887\n",
      "Epoch 668 error 0.0008713865135431801\n",
      "Epoch 669 error 0.0008707760641858032\n",
      "Epoch 670 error 0.000870166413900887\n",
      "Epoch 671 error 0.0008695575611582285\n",
      "Epoch 672 error 0.0008689495044314868\n",
      "Epoch 673 error 0.0008683422421981598\n",
      "Epoch 674 error 0.0008677357729395875\n",
      "Epoch 675 error 0.0008671300951409203\n",
      "Epoch 676 error 0.0008665252072911358\n",
      "Epoch 677 error 0.0008659211078829953\n",
      "Epoch 678 error 0.0008653177954130517\n",
      "Epoch 679 error 0.000864715268381632\n",
      "Epoch 680 error 0.0008641135252928237\n",
      "Epoch 681 error 0.0008635125646544782\n",
      "Epoch 682 error 0.0008629123849781695\n",
      "Epoch 683 error 0.0008623129847792055\n",
      "Epoch 684 error 0.0008617143625766098\n",
      "Epoch 685 error 0.000861116516893115\n",
      "Epoch 686 error 0.0008605194462551477\n",
      "Epoch 687 error 0.0008599231491928042\n",
      "Epoch 688 error 0.000859327624239867\n",
      "Epoch 689 error 0.0008587328699337592\n",
      "Epoch 690 error 0.0008581388848155727\n",
      "Epoch 691 error 0.0008575456674300298\n",
      "Epoch 692 error 0.0008569532163254568\n",
      "Epoch 693 error 0.0008563615300538218\n",
      "Epoch 694 error 0.0008557706071706783\n",
      "Epoch 695 error 0.0008551804462351882\n",
      "Epoch 696 error 0.0008545910458100733\n",
      "Epoch 697 error 0.0008540024044616426\n",
      "Epoch 698 error 0.0008534145207597501\n",
      "Epoch 699 error 0.0008528273932778083\n",
      "Epoch 700 error 0.0008522410205927542\n",
      "Epoch 701 error 0.000851655401285062\n",
      "Epoch 702 error 0.0008510705339387201\n",
      "Epoch 703 error 0.0008504864171412154\n",
      "Epoch 704 error 0.0008499030494835272\n",
      "Epoch 705 error 0.0008493204295601272\n",
      "Epoch 706 error 0.000848738555968946\n",
      "Epoch 707 error 0.0008481574273113866\n",
      "Epoch 708 error 0.0008475770421922885\n",
      "Epoch 709 error 0.0008469973992199573\n",
      "Epoch 710 error 0.0008464184970061072\n",
      "Epoch 711 error 0.0008458403341658671\n",
      "Epoch 712 error 0.0008452629093177915\n",
      "Epoch 713 error 0.0008446862210838278\n",
      "Epoch 714 error 0.0008441102680893045\n",
      "Epoch 715 error 0.0008435350489629349\n",
      "Epoch 716 error 0.0008429605623368042\n",
      "Epoch 717 error 0.0008423868068463339\n",
      "Epoch 718 error 0.0008418137811303187\n",
      "Epoch 719 error 0.0008412414838308701\n",
      "Epoch 720 error 0.000840669913593433\n",
      "Epoch 721 error 0.0008400990690667854\n",
      "Epoch 722 error 0.0008395289489029785\n",
      "Epoch 723 error 0.0008389595517573752\n",
      "Epoch 724 error 0.0008383908762886393\n",
      "Epoch 725 error 0.0008378229211586886\n",
      "Epoch 726 error 0.0008372556850327242\n",
      "Epoch 727 error 0.0008366891665791947\n",
      "Epoch 728 error 0.0008361233644697926\n",
      "Epoch 729 error 0.0008355582773794495\n",
      "Epoch 730 error 0.0008349939039863433\n",
      "Epoch 731 error 0.0008344302429718362\n",
      "Epoch 732 error 0.0008338672930205174\n",
      "Epoch 733 error 0.0008333050528201741\n",
      "Epoch 734 error 0.0008327435210617748\n",
      "Epoch 735 error 0.0008321826964394813\n",
      "Epoch 736 error 0.0008316225776505964\n",
      "Epoch 737 error 0.0008310631633956099\n",
      "Epoch 738 error 0.000830504452378147\n",
      "Epoch 739 error 0.0008299464433049837\n",
      "Epoch 740 error 0.000829389134886017\n",
      "Epoch 741 error 0.0008288325258342772\n",
      "Epoch 742 error 0.0008282766148658888\n",
      "Epoch 743 error 0.0008277214007000979\n",
      "Epoch 744 error 0.0008271668820592332\n",
      "Epoch 745 error 0.0008266130576687211\n",
      "Epoch 746 error 0.0008260599262570358\n",
      "Epoch 747 error 0.0008255074865557527\n",
      "Epoch 748 error 0.0008249557372994756\n",
      "Epoch 749 error 0.0008244046772258703\n",
      "Epoch 750 error 0.0008238543050756403\n",
      "Epoch 751 error 0.0008233046195925172\n",
      "Epoch 752 error 0.0008227556195232441\n",
      "Epoch 753 error 0.0008222073036175957\n",
      "Epoch 754 error 0.0008216596706283249\n",
      "Epoch 755 error 0.0008211127193112057\n",
      "Epoch 756 error 0.0008205664484249649\n",
      "Epoch 757 error 0.0008200208567313296\n",
      "Epoch 758 error 0.0008194759429949927\n",
      "Epoch 759 error 0.0008189317059835919\n",
      "Epoch 760 error 0.0008183881444677147\n",
      "Epoch 761 error 0.0008178452572209041\n",
      "Epoch 762 error 0.0008173030430196253\n",
      "Epoch 763 error 0.0008167615006432712\n",
      "Epoch 764 error 0.0008162206288741379\n",
      "Epoch 765 error 0.0008156804264974324\n",
      "Epoch 766 error 0.0008151408923012713\n",
      "Epoch 767 error 0.0008146020250766493\n",
      "Epoch 768 error 0.000814063823617433\n",
      "Epoch 769 error 0.0008135262867203813\n",
      "Epoch 770 error 0.000812989413185089\n",
      "Epoch 771 error 0.0008124532018140387\n",
      "Epoch 772 error 0.0008119176514125271\n",
      "Epoch 773 error 0.0008113827607887178\n",
      "Epoch 774 error 0.0008108485287535764\n",
      "Epoch 775 error 0.0008103149541209111\n",
      "Epoch 776 error 0.0008097820357073307\n",
      "Epoch 777 error 0.0008092497723322541\n",
      "Epoch 778 error 0.0008087181628179025\n",
      "Epoch 779 error 0.0008081872059892612\n",
      "Epoch 780 error 0.0008076569006741274\n",
      "Epoch 781 error 0.0008071272457030478\n",
      "Epoch 782 error 0.0008065982399093408\n",
      "Epoch 783 error 0.0008060698821290837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 784 error 0.0008055421712010876\n",
      "Epoch 785 error 0.0008050151059669174\n",
      "Epoch 786 error 0.0008044886852708701\n",
      "Epoch 787 error 0.0008039629079599542\n",
      "Epoch 788 error 0.000803437772883899\n",
      "Epoch 789 error 0.0008029132788951478\n",
      "Epoch 790 error 0.0008023894248488297\n",
      "Epoch 791 error 0.0008018662096027831\n",
      "Epoch 792 error 0.0008013436320175142\n",
      "Epoch 793 error 0.0008008216909562175\n",
      "Epoch 794 error 0.0008003003852847482\n",
      "Epoch 795 error 0.000799779713871625\n",
      "Epoch 796 error 0.0007992596755880229\n",
      "Epoch 797 error 0.0007987402693077487\n",
      "Epoch 798 error 0.0007982214939072587\n",
      "Epoch 799 error 0.0007977033482656437\n",
      "Epoch 800 error 0.0007971858312646001\n",
      "Epoch 801 error 0.0007966689417884472\n",
      "Epoch 802 error 0.0007961526787241167\n",
      "Epoch 803 error 0.0007956370409611319\n",
      "Epoch 804 error 0.000795122027391615\n",
      "Epoch 805 error 0.0007946076369102599\n",
      "Epoch 806 error 0.0007940938684143494\n",
      "Epoch 807 error 0.0007935807208037365\n",
      "Epoch 808 error 0.0007930681929808219\n",
      "Epoch 809 error 0.0007925562838505785\n",
      "Epoch 810 error 0.0007920449923205061\n",
      "Epoch 811 error 0.000791534317300669\n",
      "Epoch 812 error 0.0007910242577036541\n",
      "Epoch 813 error 0.0007905148124445558\n",
      "Epoch 814 error 0.000790005980441011\n",
      "Epoch 815 error 0.0007894977606131626\n",
      "Epoch 816 error 0.0007889901518836371\n",
      "Epoch 817 error 0.0007884831531775793\n",
      "Epoch 818 error 0.0007879767634226245\n",
      "Epoch 819 error 0.0007874709815488745\n",
      "Epoch 820 error 0.0007869658064889018\n",
      "Epoch 821 error 0.0007864612371777767\n",
      "Epoch 822 error 0.0007859572725529999\n",
      "Epoch 823 error 0.0007854539115545388\n",
      "Epoch 824 error 0.0007849511531248094\n",
      "Epoch 825 error 0.0007844489962086546\n",
      "Epoch 826 error 0.0007839474397533653\n",
      "Epoch 827 error 0.0007834464827086477\n",
      "Epoch 828 error 0.0007829461240266306\n",
      "Epoch 829 error 0.0007824463626618556\n",
      "Epoch 830 error 0.0007819471975712654\n",
      "Epoch 831 error 0.0007814486277142056\n",
      "Epoch 832 error 0.0007809506520524091\n",
      "Epoch 833 error 0.0007804532695499921\n",
      "Epoch 834 error 0.0007799564791734567\n",
      "Epoch 835 error 0.0007794602798916627\n",
      "Epoch 836 error 0.0007789646706758441\n",
      "Epoch 837 error 0.0007784696504995843\n",
      "Epoch 838 error 0.0007779752183388348\n",
      "Epoch 839 error 0.000777481373171866\n",
      "Epoch 840 error 0.0007769881139792995\n",
      "Epoch 841 error 0.0007764954397440929\n",
      "Epoch 842 error 0.0007760033494515111\n",
      "Epoch 843 error 0.000775511842089154\n",
      "Epoch 844 error 0.0007750209166469237\n",
      "Epoch 845 error 0.0007745305721170279\n",
      "Epoch 846 error 0.0007740408074939659\n",
      "Epoch 847 error 0.0007735516217745378\n",
      "Epoch 848 error 0.000773063013957824\n",
      "Epoch 849 error 0.0007725749830451883\n",
      "Epoch 850 error 0.0007720875280402607\n",
      "Epoch 851 error 0.0007716006479489379\n",
      "Epoch 852 error 0.0007711143417793796\n",
      "Epoch 853 error 0.0007706286085419862\n",
      "Epoch 854 error 0.0007701434472494276\n",
      "Epoch 855 error 0.0007696588569165814\n",
      "Epoch 856 error 0.00076917483656059\n",
      "Epoch 857 error 0.0007686913852008104\n",
      "Epoch 858 error 0.0007682085018588187\n",
      "Epoch 859 error 0.0007677261855584066\n",
      "Epoch 860 error 0.0007672444353255774\n",
      "Epoch 861 error 0.0007667632501885395\n",
      "Epoch 862 error 0.0007662826291776922\n",
      "Epoch 863 error 0.00076580257132562\n",
      "Epoch 864 error 0.0007653230756671139\n",
      "Epoch 865 error 0.0007648441412391141\n",
      "Epoch 866 error 0.0007643657670807502\n",
      "Epoch 867 error 0.0007638879522333119\n",
      "Epoch 868 error 0.000763410695740258\n",
      "Epoch 869 error 0.0007629339966471922\n",
      "Epoch 870 error 0.0007624578540018575\n",
      "Epoch 871 error 0.0007619822668541571\n",
      "Epoch 872 error 0.000761507234256123\n",
      "Epoch 873 error 0.0007610327552619037\n",
      "Epoch 874 error 0.0007605588289277958\n",
      "Epoch 875 error 0.000760085454312195\n",
      "Epoch 876 error 0.0007596126304756202\n",
      "Epoch 877 error 0.0007591403564806835\n",
      "Epoch 878 error 0.0007586686313921105\n",
      "Epoch 879 error 0.0007581974542767204\n",
      "Epoch 880 error 0.0007577268242034071\n",
      "Epoch 881 error 0.0007572567402431682\n",
      "Epoch 882 error 0.0007567872014690631\n",
      "Epoch 883 error 0.0007563182069562204\n",
      "Epoch 884 error 0.0007558497557818465\n",
      "Epoch 885 error 0.0007553818470252033\n",
      "Epoch 886 error 0.0007549144797676025\n",
      "Epoch 887 error 0.0007544476530924127\n",
      "Epoch 888 error 0.000753981366085027\n",
      "Epoch 889 error 0.000753515617832901\n",
      "Epoch 890 error 0.0007530504074255047\n",
      "Epoch 891 error 0.0007525857339543377\n",
      "Epoch 892 error 0.0007521215965129223\n",
      "Epoch 893 error 0.0007516579941967912\n",
      "Epoch 894 error 0.0007511949261034987\n",
      "Epoch 895 error 0.0007507323913325866\n",
      "Epoch 896 error 0.0007502703889855988\n",
      "Epoch 897 error 0.0007498089181660803\n",
      "Epoch 898 error 0.0007493479779795489\n",
      "Epoch 899 error 0.0007488875675335255\n",
      "Epoch 900 error 0.0007484276859374861\n",
      "Epoch 901 error 0.0007479683323028801\n",
      "Epoch 902 error 0.0007475095057431452\n",
      "Epoch 903 error 0.0007470512053736494\n",
      "Epoch 904 error 0.000746593430311737\n",
      "Epoch 905 error 0.0007461361796766801\n",
      "Epoch 906 error 0.000745679452589719\n",
      "Epoch 907 error 0.0007452232481740114\n",
      "Epoch 908 error 0.0007447675655546679\n",
      "Epoch 909 error 0.0007443124038587114\n",
      "Epoch 910 error 0.0007438577622150979\n",
      "Epoch 911 error 0.0007434036397546849\n",
      "Epoch 912 error 0.0007429500356102633\n",
      "Epoch 913 error 0.000742496948916519\n",
      "Epoch 914 error 0.0007420443788100453\n",
      "Epoch 915 error 0.0007415923244293208\n",
      "Epoch 916 error 0.0007411407849147356\n",
      "Epoch 917 error 0.0007406897594085446\n",
      "Epoch 918 error 0.0007402392470548995\n",
      "Epoch 919 error 0.0007397892469998129\n",
      "Epoch 920 error 0.0007393397583911855\n",
      "Epoch 921 error 0.0007388907803787784\n",
      "Epoch 922 error 0.0007384423121142098\n",
      "Epoch 923 error 0.0007379943527509453\n",
      "Epoch 924 error 0.0007375469014443269\n",
      "Epoch 925 error 0.0007370999573515159\n",
      "Epoch 926 error 0.0007366535196315238\n",
      "Epoch 927 error 0.0007362075874452084\n",
      "Epoch 928 error 0.000735762159955244\n",
      "Epoch 929 error 0.0007353172363261327\n",
      "Epoch 930 error 0.0007348728157242021\n",
      "Epoch 931 error 0.0007344288973175966\n",
      "Epoch 932 error 0.0007339854802762699\n",
      "Epoch 933 error 0.0007335425637719697\n",
      "Epoch 934 error 0.0007331001469782686\n",
      "Epoch 935 error 0.0007326582290705261\n",
      "Epoch 936 error 0.0007322168092258816\n",
      "Epoch 937 error 0.0007317758866232714\n",
      "Epoch 938 error 0.000731335460443415\n",
      "Epoch 939 error 0.0007308955298688036\n",
      "Epoch 940 error 0.0007304560940837144\n",
      "Epoch 941 error 0.0007300171522741654\n",
      "Epoch 942 error 0.0007295787036279604\n",
      "Epoch 943 error 0.0007291407473346573\n",
      "Epoch 944 error 0.0007287032825855703\n",
      "Epoch 945 error 0.0007282663085737375\n",
      "Epoch 946 error 0.0007278298244939778\n",
      "Epoch 947 error 0.0007273938295428233\n",
      "Epoch 948 error 0.000726958322918554\n",
      "Epoch 949 error 0.000726523303821169\n",
      "Epoch 950 error 0.0007260887714524104\n",
      "Epoch 951 error 0.0007256547250157105\n",
      "Epoch 952 error 0.0007252211637162557\n",
      "Epoch 953 error 0.0007247880867609148\n",
      "Epoch 954 error 0.0007243554933582713\n",
      "Epoch 955 error 0.000723923382718624\n",
      "Epoch 956 error 0.0007234917540539502\n",
      "Epoch 957 error 0.0007230606065779324\n",
      "Epoch 958 error 0.0007226299395059442\n",
      "Epoch 959 error 0.0007221997520550302\n",
      "Epoch 960 error 0.0007217700434439237\n",
      "Epoch 961 error 0.0007213408128930419\n",
      "Epoch 962 error 0.000720912059624455\n",
      "Epoch 963 error 0.0007204837828619158\n",
      "Epoch 964 error 0.0007200559818308224\n",
      "Epoch 965 error 0.0007196286557582507\n",
      "Epoch 966 error 0.0007192018038729093\n",
      "Epoch 967 error 0.0007187754254051803\n",
      "Epoch 968 error 0.0007183495195870566\n",
      "Epoch 969 error 0.0007179240856522078\n",
      "Epoch 970 error 0.0007174991228359116\n",
      "Epoch 971 error 0.0007170746303750907\n",
      "Epoch 972 error 0.0007166506075082887\n",
      "Epoch 973 error 0.0007162270534756789\n",
      "Epoch 974 error 0.000715803967519048\n",
      "Epoch 975 error 0.0007153813488817991\n",
      "Epoch 976 error 0.0007149591968089416\n",
      "Epoch 977 error 0.0007145375105470983\n",
      "Epoch 978 error 0.0007141162893444807\n",
      "Epoch 979 error 0.0007136955324509117\n",
      "Epoch 980 error 0.000713275239117805\n",
      "Epoch 981 error 0.0007128554085981538\n",
      "Epoch 982 error 0.0007124360401465427\n",
      "Epoch 983 error 0.0007120171330191304\n",
      "Epoch 984 error 0.0007115986864736602\n",
      "Epoch 985 error 0.0007111806997694554\n",
      "Epoch 986 error 0.0007107631721673894\n",
      "Epoch 987 error 0.0007103461029298991\n",
      "Epoch 988 error 0.0007099294913209993\n",
      "Epoch 989 error 0.0007095133366062469\n",
      "Epoch 990 error 0.0007090976380527559\n",
      "Epoch 991 error 0.0007086823949291846\n",
      "Epoch 992 error 0.0007082676065057377\n",
      "Epoch 993 error 0.0007078532720541501\n",
      "Epoch 994 error 0.0007074393908477119\n",
      "Epoch 995 error 0.0007070259621612283\n",
      "Epoch 996 error 0.000706612985271037\n",
      "Epoch 997 error 0.0007062004594550022\n",
      "Epoch 998 error 0.0007057883839924971\n",
      "Epoch 999 error 0.0007053767581644253\n",
      "       MLP result      \n",
      "Pat:          t:      out:\n",
      "0. [0 0] ---- 0 ----> 0.012\n",
      "1. [0 1] ---- 0 ----> 0.016\n",
      "2. [1 0] ---- 0 ----> 0.015\n",
      "3. [1 1] ---- 1 ----> 0.972\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "err_vector = []\n",
    "\n",
    "epochs = 1000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    count = 0\n",
    "    err = 0\n",
    "\n",
    "    for x in X:\n",
    "\n",
    "        # Feed forward\n",
    "        network[2] = feed_forward(x, network)\n",
    "\n",
    "        # Network error\n",
    "        err += net_error(t[count], network[2]['output_out'])\n",
    "\n",
    "        # Back propagation\n",
    "        network[0],network[1] = BP(x, t[count], network)\n",
    "\n",
    "        count += 1\n",
    "    print(\"Epoch {} error {}\".format(epoch,err))    \n",
    "    err_vector.append(err / X.shape[0])\n",
    "\n",
    "# Testing patterns\n",
    "testing_patterns(X, network)\n",
    "\n",
    "# Graph error\n",
    "graph_error(err_vector)\n",
    "\n",
    "# Decision boundaries\n",
    "#dec_boundaries(X, t,  network)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eDa-iuFivlv_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Tarea MLP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
